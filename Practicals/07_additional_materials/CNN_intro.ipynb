{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - introduction\n",
    "\n",
    "In this tutorial we learn how the convolutional networks work and are used in image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution for border detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T20:59:48.844288Z",
     "start_time": "2020-09-23T20:59:48.832289Z"
    }
   },
   "outputs": [],
   "source": [
    "# load eifel image\n",
    "img = mpimg.imread('eifel.jpg')\n",
    "\n",
    "# keep RGB channels\n",
    "img = img[:,:,:3]\n",
    "\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Image shape: {}'.format(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to grayscale\n",
    "# those are the exact numbers\n",
    "def rgb_to_grayscale(red, green, blue):\n",
    "    return (0.3*red + 0.59*green + 0.11*blue)\n",
    "\n",
    "# use a preprogrammed fucntion from tensorflow\n",
    "img_gray = tf.image.rgb_to_grayscale(img)\n",
    "\n",
    "# remove the last dimension and convert to numpy\n",
    "img_gray = np.array(tf.squeeze(img_gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T21:00:28.503062Z",
     "start_time": "2020-09-23T21:00:28.154031Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "plt.imshow(img_gray, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T21:07:33.397720Z",
     "start_time": "2020-09-23T21:07:33.385696Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_borders(img, mask, threshold=0.001):\n",
    "    mask_size = len(mask)\n",
    "    img_processed = np.zeros((img_gray.shape[0] - mask_size + 1, img_gray.shape[1] - mask_size + 1))\n",
    "    \n",
    "    # Apply convolution\n",
    "    for row in range(img.shape[0] - mask_size + 1):\n",
    "        for col in range(img.shape[1] - mask_size + 1):\n",
    "            img_section = img_gray[row:row+mask_size, col:col+mask_size]\n",
    "            img_processed[row, col] = sum(sum((img_section * mask)))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    plt.imshow(img_processed, cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    img_processed = 1 - (img_processed > threshold).astype(int)            \n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    plt.imshow(img_processed, cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T21:08:01.167481Z",
     "start_time": "2020-09-23T21:07:57.078957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify vertical borders\n",
    "mask = [\n",
    "    [-1,  0,  1],\n",
    "    [-2,  0,  2],\n",
    "    [-1,  0,  1]\n",
    "]\n",
    "\n",
    "detect_borders(img, mask, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify horizontal borders\n",
    "mask = [\n",
    "    [-1,  0,  1],\n",
    "    [-2,  0,  2],\n",
    "    [-1,  0,  1]\n",
    "]\n",
    "\n",
    "detect_borders(img, np.transpose(mask), threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace edge detector, should do both horizontal and vertical\n",
    "\n",
    "mask = [\n",
    "    [0,  1,  0],\n",
    "    [1,  -4, 1],\n",
    "    [0,  1,  0]\n",
    "]\n",
    "\n",
    "detect_borders(img, np.transpose(mask), threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with negative sign\n",
    "mask = [\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "]\n",
    "\n",
    "detect_borders(img, mask, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T21:10:06.783630Z",
     "start_time": "2020-09-23T21:10:01.443630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify changes around a point\n",
    "mask = [\n",
    "    [0,   0,  -1,   0,   0],\n",
    "    [0,  -1,  -2,  -1,   0],\n",
    "    [-1, -2,  16,  -2,  -1],\n",
    "    [0,  -1,  -2,  -1,   0],\n",
    "    [0,   0,  -1,   0,   0]\n",
    "]\n",
    "\n",
    "detect_borders(img, mask, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = [\n",
    "    [1,   2,  1,],\n",
    "    [2,   4,  2,] ,\n",
    "    [1,   2,  1,]  \n",
    "]\n",
    "\n",
    "detect_borders(img, mask, threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Try you own masks e.g. for sharpening an image, bluring it etc.</span>\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kernel_(image_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and processing\n",
    "\n",
    "Tensoflow contains several datasets for image classification\n",
    " - https://www.tensorflow.org/datasets/catalog/overview\n",
    " \n",
    "Useful guide for image processing:\n",
    " - https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    " \n",
    "We have two options:\n",
    " 1. Use keras processing layers - make them as a part of the network\n",
    " 2. Apply transformation on tf.data.Dataset using .map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to supress the progress bar\n",
    "# tfds.disable_progress_bar()\n",
    "\n",
    "# Load the cat vs dogs data\n",
    "cats_vs_dogs = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    split=\"train\",\n",
    "    as_supervised=True, # Include labels\n",
    "    shuffle_files=False # Change to true for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_vs_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for the Tensorflow Dataset\n",
    "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(cats_vs_dogs.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy())\n",
    "    plt.title(int(label))\n",
    "    plt.axis('off')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the mnist data\n",
    "mnist_train, mnist_dev = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    as_supervised=True, # Include labels\n",
    "    shuffle_files=False # Change to true for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(mnist_train.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy())\n",
    "    plt.title(int(label))\n",
    "    plt.axis('off')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cats_vs_dogs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot normal picture\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "for image, label in cats_vs_dogs.take(1):\n",
    "    plt.imshow(image.numpy())\n",
    "    plt.axis('off')\n",
    "    plt.plot()\n",
    "    \n",
    "# Plot resized picture\n",
    "size = (128, 128)\n",
    "resized_cvd = cats_vs_dogs.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "for image, label in resized_cvd.take(1):\n",
    "    plt.imshow(image.numpy().astype(\"int32\"))\n",
    "    plt.axis('off')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation of the pre-processing functions\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
    "\n",
    "Image data augmentation: These layers apply random augmentation transforms to a batch of images. They are only active during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augemtation\n",
    "resized_cvd = cats_vs_dogs.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "\n",
    "dog_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in resized_cvd.take(1):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    first_image = images\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(4, 3, i + 1)\n",
    "        augmented_image = dog_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_aug = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.5),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1, 0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = mnist_train.cache().batch(5).prefetch(buffer_size=10)\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for first_image in images[0:5]:\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        for i in range(12):\n",
    "            ax = plt.subplot(4, 3, i + 1)\n",
    "            augmented_image = mnist_aug(\n",
    "                tf.expand_dims(first_image, 0), training=True\n",
    "            )\n",
    "            plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNNs\n",
    "\n",
    "A tutorial dedicated to CNNs and images:\n",
    " - https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist\n",
    "Low resolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN\n",
    " - With sequential API\n",
    " - Two blocks of convolutions with max pooling and a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture:\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# First convolution block\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation='relu',\n",
    "                                 input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "# Second convolution block\n",
    "model.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*7*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: To make the following line work you need to install graphviz (if you have not done so in one of the previous classes)\n",
    "# 1) follow the instructions https://graphviz.gitlab.io/download/?fbclid=IwAR1V-lrRhho5rSfBVYXYISsighqRwOCOgMHLmL_DclkQrPtMXQaKj3mFcqs\n",
    "# 2) this notebook has been tested with version 8.0.3\n",
    "# 3) make sure you add it to the PATH variable (you are specifically asked during the installation) at least for local user\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist data\n",
    "mnist_train, mnist_dev = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    as_supervised=True, # Include labels\n",
    "    shuffle_files=False # Change to true for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches from the dataset\n",
    "batch_size = 128\n",
    "\n",
    "train_ds = mnist_train.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "#train_ds = mnist_train.cache().batch(batch_size).prefetch(buffer_size=10).map(lambda x,y: (mnist_aug(x), y))\n",
    "validation_ds = mnist_dev.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on what should be the numbers that we see during the training: \"For training loss, keras does a running average over the batches. For validation loss, a conventional average over all the batches in validation data is performed. The training accuracy is the average of the accuracy values for each batch of training data during training.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/mnist_simple')\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to get prediction manually\n",
    "prediction = model.predict(validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have softmax actiovation, so we get 10 probabilities\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we probably want to select the label with the highest predicted probability as our prediction\n",
    "np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger CNN with regularization\n",
    " - With functional API\n",
    " - Increase number of convolution layers and channels\n",
    " - Uses label smoothing, dropout, L2, early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label smoothing\n",
    "\n",
    "def label_smooth_train(image, labels, alpha, n_labels):\n",
    "    labels = tf.one_hot(tf.cast(labels, tf.int32), n_labels)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    labels *= (1 - alpha)\n",
    "    labels += alpha / n_labels\n",
    "    return image, labels\n",
    "\n",
    "def label_smooth_dev(image, labels, n_labels):\n",
    "    labels = tf.one_hot(tf.cast(labels, tf.int32), n_labels)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a bigger CNN\n",
    "reg = tf.keras.regularizers.L1L2(l2=0.001)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[28, 28, 1])\n",
    "\n",
    "# Augment data - creates distortion in the evaluation data as well (not good for well centered mnist)\n",
    "# x = mnist_aug(inputs)\n",
    "\n",
    "# First convolution block\n",
    "x = tf.keras.layers.Conv2D(filters=16,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=reg)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=reg)(x)\n",
    "\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Second convolution block\n",
    "x = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 kernel_regularizer=reg,\n",
    "                                 activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=64,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 kernel_regularizer=reg,\n",
    "                                 activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Hidden layer\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches with label smoothing\n",
    "batch_size = 128\n",
    "smooth_alpha = 0.05\n",
    "n_labels = 10\n",
    "\n",
    "train_ds = mnist_train.map(lambda x, y: label_smooth_train(x, y, smooth_alpha, n_labels))\n",
    "validation_ds = mnist_dev.map(lambda x, y: label_smooth_dev(x, y, n_labels))\n",
    "\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model - label smoothing -> no sparse loss and metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=tf.keras.metrics.CategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy', patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/mnist_regularized')\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_ds,\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats vs dogs\n",
    "Higher resolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper network with regularization\n",
    " - Uses data_augmentation, label smoothing, dropout, L2, early stopping, batch normalization, global pooling at the end\n",
    " - Functional API used\n",
    " \n",
    "Batch norm layer has training and inference mode, and has also trainable and non-trainable params, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = tf.keras.regularizers.L1L2(l2=0.0001)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "\n",
    "# Apply data augemtantion\n",
    "x = dog_augmentation(inputs)\n",
    "\n",
    "# First convolution block (64 x 64)\n",
    "x = tf.keras.layers.Conv2D(filters=16,\n",
    "                           kernel_size=3,\n",
    "                           strides=2,\n",
    "                           padding='same',\n",
    "                           kernel_regularizer=reg)(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Second convolution block (32 x 32)\n",
    "x = tf.keras.layers.Conv2D(filters=32,\n",
    "                           kernel_size=3,\n",
    "                           strides=1,\n",
    "                           padding='same',\n",
    "                           kernel_regularizer=reg)(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Third convolution block (16 x 16)\n",
    "x = tf.keras.layers.Conv2D(filters=64,\n",
    "                           kernel_size=3,\n",
    "                           strides=1,\n",
    "                           padding='same',\n",
    "                           kernel_regularizer=reg)(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Fourth convolution block (8 x 8)\n",
    "x = tf.keras.layers.Conv2D(filters=128,\n",
    "                           kernel_size=3,\n",
    "                           strides=1,\n",
    "                           padding='same',\n",
    "                           kernel_regularizer=reg)(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "\n",
    "# Apply global average pooling\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dropout and fully connected\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# There are some non-trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation data and batches\n",
    "train_size = 10000\n",
    "valid_size = 2000\n",
    "batch_size = 128\n",
    "image_size = (128, 128)\n",
    "\n",
    "train_ds = cats_vs_dogs.take(train_size)\n",
    "rest = cats_vs_dogs.skip(train_size)\n",
    "validation_ds = rest.take(valid_size)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, image_size), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, image_size), y))\n",
    "\n",
    "# Could also apply label smoothing\n",
    "# smooth_alpha = 0.01\n",
    "# n_labels = 2\n",
    "# train_ds = train_ds.map(lambda x, y: label_smooth_train(x, y, smooth_alpha, n_labels))\n",
    "# validation_ds = validation_ds.map(lambda x, y: label_smooth_dev(x, y, n_labels))\n",
    "\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model - label smoothing -> no sparse loss and metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=tf.keras.metrics.BinaryAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy', patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/cats_vs_dogs')\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_ds,\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** CIFAR 10</span>\n",
    "\n",
    "Try to build you own convolutional network on CIFAR 10 dataset using residual connection and other features from the presented CNNs\n",
    "\n",
    "see https://www.tensorflow.org/guide/keras/functional#a_toy_resnet_model - includes example with loading the cifar10 dataset and the usage of functional api for the residual connection\n",
    "\n",
    "Optionally, you can add the data augmentation at the beginning of the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
