{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a635c4a6",
   "metadata": {},
   "source": [
    "# Face recongnition\n",
    "In this notebook, we use already trained neural networks for face recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a90646",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8386e78",
   "metadata": {},
   "source": [
    "Download the data from <a href=\"https://www2.karlin.mff.cuni.cz/~kozmikk/files/face_recognition.zip\" target=\"_blank\"> face recongnition images</a> and unpack it to the Data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979483c2",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d07984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835df275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe6334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:37:54.184084Z",
     "start_time": "2021-09-07T14:37:12.464092Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import mtcnn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae2354",
   "metadata": {},
   "source": [
    "# Detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:37:54.232079Z",
     "start_time": "2021-09-07T14:37:54.202079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract faces function using mtcnn\n",
    "\n",
    "def extract_face(filename, required_size=(160, 160), rotate=None, display_img=True):\n",
    "    image = Image.open(f'./../../Data/face_recognition/{filename}')\n",
    "    image = image.convert('RGB')\n",
    "    print(f'Loaded image of shape ({image.size[0]}, {image.size[1]}):')\n",
    "    pixels = np.asarray(image)\n",
    "    if display_img:\n",
    "        plt.imshow(pixels)\n",
    "        plt.show()\n",
    "    \n",
    "    if rotate:\n",
    "        print(f'Warrning: Rotationg image by {rotate} degrees!')\n",
    "        image = image.rotate(rotate)\n",
    "        pixels = np.asarray(image)\n",
    "        if display_img:\n",
    "            plt.imshow(pixels)\n",
    "            plt.show()\n",
    "        \n",
    "    detector = mtcnn.MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "    \n",
    "    n_faces = len(results)\n",
    "    if n_faces == 1:\n",
    "        print(f'Face detector discovered {n_faces} face.')\n",
    "    else:\n",
    "        print(f'Face detector discovered {n_faces} faces.')\n",
    "    \n",
    "    if n_faces == 0:\n",
    "        return None\n",
    "    \n",
    "    if display_img:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(pixels)\n",
    "    \n",
    "    for i in range(n_faces-1,-1,-1):\n",
    "        x1, y1, width, height = results[i]['box']\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2 = x1 + width\n",
    "        y2 = y1 + height\n",
    "        \n",
    "        if display_img:\n",
    "            left_eye = results[i]['keypoints']['left_eye']\n",
    "            right_eye = results[i]['keypoints']['right_eye']\n",
    "            nose = results[i]['keypoints']['nose']\n",
    "            mouth_left = results[i]['keypoints']['mouth_left']\n",
    "            mouth_right = results[i]['keypoints']['mouth_right']\n",
    "            confidence = results[i]['confidence']\n",
    "\n",
    "    #         color = (10/255, 134/255, 132/255)\n",
    "            color='red'\n",
    "            lw = round(width * 10 / image.size[1])\n",
    "\n",
    "            plt.plot([x1, x2], [y1, y1], color=color, ls='-', lw=max(3,lw))\n",
    "            plt.plot([x1, x2], [y2, y2], color=color, ls='-', lw=max(3,lw))\n",
    "            plt.plot([x1, x1], [y1, y2], color=color, ls='-', lw=max(3,lw))\n",
    "            plt.plot([x2, x2], [y1, y2], color=color, ls='-', lw=max(3,lw))\n",
    "            plt.annotate(f'{confidence:.5f}', (x2+10, y1-10), color=color, fontsize=20)\n",
    "\n",
    "            plt.scatter([left_eye[0], right_eye[0]],[left_eye[1], right_eye[1]], marker='o', s=lw*200, alpha=0.5, color=color)\n",
    "            plt.scatter([nose[0]],[nose[1]], marker='o', s=lw*200, alpha=0.5, color=color)\n",
    "            plt.plot([mouth_left[0], mouth_right[0]], [mouth_left[1], mouth_right[1]], color=color, ls='-', lw=lw)\n",
    "        \n",
    "    if display_img:\n",
    "        plt.show()\n",
    "    \n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    \n",
    "    if display_img:\n",
    "        plt.imshow(face_array)\n",
    "        plt.show()\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2c8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:27:42.572614Z",
     "start_time": "2021-08-30T08:27:33.887369Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check one picture\n",
    "\n",
    "face = extract_face('faces4.jpg', rotate=None, display_img=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f785b07",
   "metadata": {},
   "source": [
    "- Visit https://github.com/nyoki-mtl/keras-facenet/blob/master/code/inception_resnet_v1.py\n",
    "- download model and weights from https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn\n",
    "- save it to ./facenet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd51cfb",
   "metadata": {},
   "source": [
    "# Encode face in feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec2b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:27:59.174271Z",
     "start_time": "2021-08-30T08:27:54.117567Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copied code, check the InceptionResNet architecture\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Inception-ResNet V1 model for Keras.\n",
    "# Reference\n",
    "http://arxiv.org/abs/1602.07261\n",
    "https://github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v1.py\n",
    "https://github.com/myutwo150/keras-inception-resnet-v2/blob/master/inception_resnet_v2.py\n",
    "\"\"\"\n",
    "from functools import partial\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import add\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def scaling(x, scale):\n",
    "    return x * scale\n",
    "\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               use_bias=use_bias,\n",
    "               name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n",
    "        x = BatchNormalization(axis=bn_axis, momentum=0.995, epsilon=0.001,\n",
    "                               scale=False, name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = _generate_layer_name('Activation', prefix=name)\n",
    "        x = Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _generate_layer_name(name, branch_idx=None, prefix=None):\n",
    "    if prefix is None:\n",
    "        return None\n",
    "    if branch_idx is None:\n",
    "        return '_'.join((prefix, name))\n",
    "    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n",
    "\n",
    "\n",
    "def _inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    if block_idx is None:\n",
    "        prefix = None\n",
    "    else:\n",
    "        prefix = '_'.join((block_type, str(block_idx)))\n",
    "    name_fmt = partial(_generate_layer_name, prefix=prefix)\n",
    "\n",
    "    if block_type == 'Block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Block17':\n",
    "        branch_0 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [1, 7], name=name_fmt('Conv2d_0b_1x7', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [7, 1], name=name_fmt('Conv2d_0c_7x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [1, 3], name=name_fmt('Conv2d_0b_1x3', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [3, 1], name=name_fmt('Conv2d_0c_3x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    mixed = Concatenate(axis=channel_axis, name=name_fmt('Concatenate'))(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                   K.int_shape(x)[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=name_fmt('Conv2d_1x1'))\n",
    "    up = Lambda(scaling,\n",
    "                output_shape=K.int_shape(up)[1:],\n",
    "                arguments={'scale': scale})(up)\n",
    "    x = add([x, up])\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=name_fmt('Activation'))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionResNetV1(input_shape=(160, 160, 3),\n",
    "                      classes=128,\n",
    "                      dropout_keep_prob=0.8,\n",
    "                      weights_path=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = conv2d_bn(inputs, 32, 3, strides=2, padding='valid', name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n",
    "    x = conv2d_bn(x, 256, 3, strides=2, padding='valid', name='Conv2d_4b_3x3')\n",
    "\n",
    "    # 5x Block35 (Inception-ResNet-A block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.17,\n",
    "                                    block_type='Block35',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n",
    "    branch_0 = conv2d_bn(x,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 192, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n",
    "\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    for block_idx in range(1, 11):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.1,\n",
    "                                    block_type='Block17',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n",
    "    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n",
    "    branch_0 = conv2d_bn(branch_0,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 2))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n",
    "\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.2,\n",
    "                                    block_type='Block8',\n",
    "                                    block_idx=block_idx)\n",
    "    x = _inception_resnet_block(x,\n",
    "                                scale=1.,\n",
    "                                activation=None,\n",
    "                                block_type='Block8',\n",
    "                                block_idx=6)\n",
    "\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "    x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(classes, use_bias=False, name='Bottleneck')(x)\n",
    "    bn_name = _generate_layer_name('BatchNorm', prefix='Bottleneck')\n",
    "    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False,\n",
    "                           name=bn_name)(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name='inception_resnet_v1')\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = InceptionResNetV1(weights_path='facenet_model/weights/facenet_keras_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c41b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42f597",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the model\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38c7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:28:48.454112Z",
     "start_time": "2021-08-30T08:27:59.223091Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# processing and normalization\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "images = {\n",
    "    'face1.jpg': 'Marek',\n",
    "    'face2.jpg': 'Marek',\n",
    "    'faces1.jpg': 'Marek',\n",
    "    'faces4.jpg': 'Marek',\n",
    "    'face3.jpg': 'Marek\\'s father',\n",
    "    'face6.jpg': 'Marek\\'s father',\n",
    "    'face4.jpg': 'Kuba',\n",
    "    'face5.jpg': 'Kuba',    \n",
    "    'faces2.jpg': 'Kuba',\n",
    "    'faces3.jpg': 'Kiki',\n",
    "    \n",
    "}\n",
    "\n",
    "normalizer = Normalizer(norm='l2')\n",
    "\n",
    "feat_space = {}\n",
    "for img, lbl in tqdm(images.items()):\n",
    "    if img == 'face1.jpg':\n",
    "        face = extract_face(img, rotate=90, display_img=False)\n",
    "    else:\n",
    "        face = extract_face(img, rotate=None, display_img=False)\n",
    "        \n",
    "    # normalize face\n",
    "    face = face.astype('float32')\n",
    "    mean = face.mean()\n",
    "    std = face.std()\n",
    "    face = (face - mean) / std\n",
    "    \n",
    "    samples = np.expand_dims(face, axis=0)\n",
    "    fs = model.predict(samples)\n",
    "    fs = normalizer.transform(fs)\n",
    "    feat_space[img] = list(fs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598e57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the feature space\n",
    "\n",
    "len(feat_space['face1.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071e695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:28:49.485169Z",
     "start_time": "2021-08-30T08:28:48.532980Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get distances between the faces encoded in the feature space\n",
    "\n",
    "distances = pd.DataFrame(columns=images, index = images)\n",
    "\n",
    "for img1 in images:\n",
    "    for img2 in images:\n",
    "        distances.loc[img1, img2] = np.linalg.norm(np.array(feat_space[img1]) - np.array(feat_space[img2]))\n",
    "        \n",
    "distances = distances.astype(float)\n",
    "\n",
    "plt.figure(figsize=(9,8))\n",
    "sns.heatmap(distances, annot=True, fmt='.2f', vmin=0.5, xticklabels=list(images.values()), yticklabels=list(images.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2d5e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:51:59.402110Z",
     "start_time": "2021-08-29T09:51:59.383113Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put in into numpy array\n",
    "\n",
    "dt = np.ndarray(shape=(len(feat_space),len(feat_space['face1.jpg'])))\n",
    "i = 0\n",
    "for img, fs in feat_space.items():\n",
    "    dt[i, :] = fs\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02c77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:52:00.851267Z",
     "start_time": "2021-08-29T09:52:00.616269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply PCA fot display the distance in 2D\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show, output_notebook\n",
    "\n",
    "\n",
    "# defining the chart\n",
    "output_notebook()\n",
    "plot_tfidf = bp.figure(plot_width = 700, plot_height = 600, title=\"Face feature space\",\n",
    "    tools=\"pan,reset,hover\",\n",
    "    x_axis_type = None, y_axis_type = None, min_border = 1)\n",
    "\n",
    "# dimensionality reduction. converting the vectors to 2d vectors\n",
    "pca = PCA(n_components = 2)\n",
    "pca_enc = pca.fit(dt).transform(dt)\n",
    "\n",
    "# putting everything in a dataframe\n",
    "pca_df = pd.DataFrame(pca_enc, columns=['x', 'y'])\n",
    "pca_df['person'] = list(images.values())\n",
    "\n",
    "# plotting. the corresponding word appears when you hover on the data point.\n",
    "plot_tfidf.scatter(x = 'x', y = 'y', source = pca_df)\n",
    "hover = plot_tfidf.select(dict(type = HoverTool))\n",
    "hover.tooltips = {\"person\": \"@person\"}\n",
    "show(plot_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7a4ae",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Get your own photos or download some from the internet. Try to think of some interesting combinations, circumstances etc. What distance threshold would you choose to consider 2 faces to belong to the same person?</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "152.667px",
    "width": "539.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
