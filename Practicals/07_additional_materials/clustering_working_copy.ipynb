{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6755fd",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59229417",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this tutorial we learn how to cluster data into homogenuous groups. We inspect both supervised and unsupervised machine learning approaches.\n",
    "\n",
    "We proceed as follows:\n",
    "\n",
    "- generate datasets\n",
    "- create clusters using hierarchical clustering\n",
    "    - visualisation of results for different algorithm parameters\n",
    "    - visualisation of decision tree\n",
    "- create clusters using k-means clustering\n",
    "- predict continuous target using k-nearest neighbor algorithm\n",
    "    \n",
    "Additional resources:\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "- https://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py\n",
    "- https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab27370",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350a4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # plot styling\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_s_curve # data generation\n",
    "from sklearn.datasets import make_blobs # data generation\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "from itertools import cycle, islice\n",
    "\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f90bc",
   "metadata": {},
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50e53a",
   "metadata": {},
   "source": [
    "We generate three structured sets of points in two-dimensional plane:\n",
    "\n",
    "- data_circles consists of several circles inside each of other\n",
    "- data_moons consists of two moons\n",
    "- data_blobs consists of several blobs\n",
    "\n",
    "Finally, we also denote generate points in rectangle from uniform distribution. This dataset will represent unstructured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b56f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(18)\n",
    "n_samples = 1500 # Number of points generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fe371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate two circles, one within the other\n",
    "\n",
    "data_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.08, random_state=18)\n",
    "plt.scatter(data_circles[0][:, 0], data_circles[0][:, 1], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4831d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate two moons\n",
    "\n",
    "data_moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=18)\n",
    "plt.scatter(data_moons[0][:, 0], data_moons[0][:, 1], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e3efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate several bobs\n",
    "\n",
    "data_blobs = datasets.make_blobs(n_samples=n_samples, centers=6, cluster_std=[1, 0.4, 0.6, 0.8, 0.5, 0.5], random_state=18)\n",
    "plt.scatter(data_blobs[0][:, 0], data_blobs[0][:, 1], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate uniformly distributed points\n",
    "\n",
    "data_random = np.random.rand(n_samples, 2), None\n",
    "plt.scatter(data_random[0][:, 0], data_random[0][:, 1], s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd97564",
   "metadata": {},
   "source": [
    "# Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb6988",
   "metadata": {},
   "source": [
    "We investigate hierarchical clustering as implemented in sklearn\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "It performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. In every step we find two clusters with the lowest measure of dissimilarity and merge them until either\n",
    "\n",
    "- only 'n_cluster' clusters is produced,\n",
    "- dissimilarity for the most similar clusters do not attain 'distance_threshold' parameter,\n",
    "\n",
    "depending on the parameter chosen.\n",
    "\n",
    "Dissimilarity is measured using one of the following distances\n",
    "\n",
    "- “l1”, “euclidean”, “cosine”, or “precomputed”\n",
    "\n",
    "with obvious meaning. Dissimilarity of two clusters is then computed based on distances among data points in one of the following ways:\n",
    "\n",
    "- 'Complete' maximum distance between observations of pairs of clusters.\n",
    "- 'Average' average of the distances between all observations of pairs of clusters.\n",
    "- 'Single' minimum distance between observations of pairs of clusters.\n",
    "- 'Ward': variance of data points within new cluster\n",
    "\n",
    "Note that due to implementation limitations, several combinations of distance-aggregation method are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d672b",
   "metadata": {},
   "source": [
    "## Linkage\n",
    "\n",
    "We inspect influence of aggregation of distances (so called linkage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e76278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Adjust the following parameters and discuss the resulting clusters computed in the following cell.\n",
    "n_cluster = 4 # Create 'n_cluster' clusters\n",
    "distance_threshold = None # Create clusters until 'distance_threshold' is reached\n",
    "\n",
    "# Important note: Exactly one of the above two parameters has to be set to 'None'\n",
    "\n",
    "# TODO: Answer why for 'n_cluster'==4, 'linkage'=='single' the moons are separated, while for other linkages it is not.\n",
    "# TODO: 'distance_threshold' is a paremeter whose optimal value depends on the dataset. Identify the function/method that we used to tackle this problem in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806635b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cluster parameters\n",
    "plt.figure(figsize=(9 * 1.3 + 2, 14.5))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.96, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "# Init test datasets\n",
    "datasets = [data_circles, data_moons, data_blobs, data_random]\n",
    "\n",
    "# Iterate over different algorithm settings\n",
    "plot_num = 1\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters=n_cluster, linkage=\"ward\", distance_threshold=distance_threshold\n",
    "    )\n",
    "    complete = cluster.AgglomerativeClustering(\n",
    "        n_clusters=n_cluster, linkage=\"complete\", distance_threshold=distance_threshold\n",
    "    )\n",
    "    average = cluster.AgglomerativeClustering(\n",
    "        n_clusters=n_cluster, linkage=\"average\", distance_threshold=distance_threshold\n",
    "    )\n",
    "    single = cluster.AgglomerativeClustering(\n",
    "        n_clusters=n_cluster, linkage=\"single\", distance_threshold=distance_threshold\n",
    "    )\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        (\"Single Linkage\", single),\n",
    "        (\"Average Linkage\", average),\n",
    "        (\"Complete Linkage\", complete),\n",
    "        (\"Ward Linkage\", ward),\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \"\n",
    "                + \"connectivity matrix is [0-9]{1,2}\"\n",
    "                + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2d723",
   "metadata": {},
   "source": [
    "## Number of clusters\n",
    "\n",
    "The parameter 'n_clusters' is essential as can if we visualise results for different values of this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9dd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Adjust the following parameters and discuss influence on the results.\n",
    "n_clusters = [\n",
    "    3, 4, 5, 6\n",
    "]\n",
    "# Considered clusters counts (Note: for implementation reasons it should be len(n_clusters)==4)\n",
    "\n",
    "# Considered linkage\n",
    "linkage = \"ward\"\n",
    "\n",
    "# Considered metric\n",
    "metric = \"euclidean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cluster parameters\n",
    "plt.figure(figsize=(9 * 1.3 + 2, 14.5))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.96, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "# Init test datasets\n",
    "datasets = [data_circles, data_moons, data_blobs, data_random]\n",
    "\n",
    "\n",
    "# Iterate over different algorithm settings\n",
    "plot_num = 1\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    for n_cluster in n_clusters:\n",
    "        \n",
    "        algorithm = cluster.AgglomerativeClustering(\n",
    "            n_clusters=n_cluster, linkage=linkage, metric=metric\n",
    "        )\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \"\n",
    "                + \"connectivity matrix is [0-9]{1,2}\"\n",
    "                + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(\"n_cluster==\" + str(n_cluster), size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "        \n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9dd5c",
   "metadata": {},
   "source": [
    "## Distances\n",
    "\n",
    "We visualise results for different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494fc00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Adjust the following parameters and discuss influence on the results.\n",
    "n_cluster = 3\n",
    "linkage = \"complete\"\n",
    "metrics = [\"l1\", \"euclidean\"] # Note: for linkage==\"ward\" only \"euclidean\" is accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cad19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up cluster parameters\n",
    "plt.figure(figsize=(9 * 1.3 + 2, 14.5))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.96, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "\n",
    "# Init test datasets\n",
    "datasets = [\n",
    "    data_circles, data_moons, data_blobs, data_random\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate over different algorithm settings\n",
    "plot_num = 1\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    for metric in metrics:\n",
    "        \n",
    "        algorithm = cluster.AgglomerativeClustering(\n",
    "            n_clusters=n_cluster, linkage=linkage, metric=metric\n",
    "        )\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \"\n",
    "                + \"connectivity matrix is [0-9]{1,2}\"\n",
    "                + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(\"metric==\" + metric, size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce02f4a",
   "metadata": {},
   "source": [
    "## Dendrogram\n",
    "\n",
    "A tree-like structure that fully represents the hierarchical model.\n",
    "\n",
    "Every leaf represents single data point and every node represents cluster that contains all data points in its subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76e5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, truncate_mode=\"level\", p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust parameters 'n–clusters' or 'distance_threshold' and comparing the results, explain produced dendrogram.\n",
    "\n",
    "distance_threshold=10\n",
    "n_clusters=None\n",
    "# Note: exactly one of 'distance_threshold', 'n_clusters' has to be set to 'None'\n",
    "\n",
    "# Fit\n",
    "X, y = data_blobs\n",
    "model = cluster.AgglomerativeClustering(distance_threshold=distance_threshold, n_clusters=n_clusters, linkage=\"average\", compute_distances=True)\n",
    "model = model.fit(X)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "y_pred = model.labels_.astype(int)\n",
    "\n",
    "colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "plt.show()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plot_dendrogram(model)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81259932",
   "metadata": {},
   "source": [
    "## Hierarchical clustering in seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e7661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=20, \n",
    "    n_features=15, \n",
    "    n_informative=2, \n",
    "    n_redundant=5, \n",
    "    n_repeated=2,\n",
    "    n_classes=2,\n",
    "    flip_y=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae945c-d725-4e42-b230-2ade14b5ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.6)\n",
    "sns.clustermap(X, method=\"complete\", metric=\"correlation\", annot=True, cmap='GnBu',\n",
    "               annot_kws={\"size\": 7}, figsize=(15,12));\n",
    "\n",
    "sns.set(font_scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e157b5",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "Unsupervised clustering algorithm.\n",
    "\n",
    "Starts with initialized centroids and using specified distance run iterations as follows:\n",
    "\n",
    "- assign the nearest centroid for every data point\n",
    "- adjust centroids so that they represent 'their' data points.\n",
    "\n",
    "Either number of iterations or some distance threshold is given as a stopping criterion. Many variants of this algorithm exist as distance or adjustment method may vary. In the sequel we provide implementation and visualisation of our own of this simple algorithm\n",
    "\n",
    "Note that after unsupervised training, one can use the trained centroids for future prediction of unseen data points in the obvious way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a8f56",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeadca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_centroid(centroids, x, y):\n",
    "    \n",
    "    \"\"\"\n",
    "        Return index of nearest centroid to given point\n",
    "        \n",
    "        Args:\n",
    "            - centroids: list of centroids represented by tuples\n",
    "            - x: first component of a given point\n",
    "            - y: second component of a given point\n",
    "            \n",
    "        Returns:\n",
    "            int: index of the nearest centroid from the list 'centroids'\n",
    "    \"\"\"\n",
    "    \n",
    "    i_min = -1\n",
    "    dist_min = np.inf\n",
    "    for i, centroid in enumerate(centroids):\n",
    "    \n",
    "        dist = (abs(centroid[0]-x))**2+(abs(centroid[1]-y))**2\n",
    "        \n",
    "        if dist < dist_min:\n",
    "            i_min = i\n",
    "            dist_min = dist\n",
    "            \n",
    "    if i_min == -1:\n",
    "        print('Unexpected result.')\n",
    "    else:\n",
    "        return i_min\n",
    "    \n",
    "def init_centroid(data, k_cluster):\n",
    "    \n",
    "    \"\"\"\n",
    "        Returns list of centroids as initialization for k-means algorithm.\n",
    "        Centroids are generated from uniform distribution in the observation window.\n",
    "    \n",
    "        Args:\n",
    "            - data: dataset considered for k-means, dataframe that contains columns 'x', 'y'\n",
    "            - k_cluster: number of centroids to be generated\n",
    "    \n",
    "        Returns:\n",
    "            list: list of tuples representing generated centroids\n",
    "    \"\"\"\n",
    "    \n",
    "    x_max, y_max = data['x'].max(), data['y'].max()\n",
    "    x_min, y_min = data['x'].min(), data['y'].min()\n",
    "\n",
    "    centroids = [\n",
    "        (np.random.uniform(x_min, x_max), np.random.uniform(y_min, y_max)) for i in range(k_cluster)\n",
    "    ]\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec768e",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f393af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_kmeans = pd.DataFrame({'x': data_blobs[0][:, 0], 'y': data_blobs[0][:, 1]}) # Considered data\n",
    "k_cluster = 5 # Number of clusters\n",
    "i_iter = 4 # Number of iterations\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66435e2",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee52036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroids = init_centroid(data_kmeans, k_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e16d3",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "We visualise every iteration of the algorithm. Two phases in every iteration:\n",
    "\n",
    "- find the nearest neighbor\n",
    "- adjust centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a87f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Complete all necessary steps in the following loop.\n",
    "\n",
    "# Plot init\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(data_kmeans['x'], data_kmeans['y'], c='grey', s=50)\n",
    "plt.scatter([a[0] for a in centroids], [a[1] for a in centroids], c='red', s=200)\n",
    "plt.title(\"Initialization\", fontsize=45)\n",
    "plt.show()\n",
    "\n",
    "for i in range(i_iter):\n",
    "    \n",
    "    # TODO: use 'get_centroid' to store the nearest centroid for every point in 'data_kmens' as a column 'centroid'\n",
    "    ...\n",
    "    \n",
    "    # Plot the 'find the nearest neighbor' phase\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data_kmeans['x'], data_kmeans['y'], c=data_kmeans['centroid'], s=50, cmap='viridis')\n",
    "    plt.scatter([a[0] for a in centroids], [a[1] for a in centroids], c='red', s=200)\n",
    "    plt.title(\"Iteration \" + str(i+1) + \": find centroids\", fontsize=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # TODO: Compute new centroids (store as dataframe 'centroids' with columns 'x', 'y')\n",
    "    ...\n",
    "    \n",
    "    # Plot the 'adjust centroids' phase\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data_kmeans['x'], data_kmeans['y'], c=data_kmeans['centroid'], s=50, cmap='viridis')\n",
    "    plt.scatter(centroids['x'], centroids['y'], c='red', s=200, alpha=0.9)\n",
    "    plt.title(\"Iteration \" + str(i+1) + \": adjust centroids\", fontsize=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save centroids as list\n",
    "    centroids = centroids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a462b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Consider different aggregation techniques in the above loop for computing centroids and discuss their behavior\n",
    "# TODO: For 'k_cluster'==5, 'i_iter'==4, np.random.seed(21) we obtain only 4 clusters. Discuss why.\n",
    "# TODO: Adjust 'get_centroid' so that different metric is considered and observe possible changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42aae3c",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "We add data point far away from our original dataset and observe changes in the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b563bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## K-means outliers\n",
    "data_kmeans = pd.DataFrame({'x': data_blobs[0][:, 0], 'y': data_blobs[0][:, 1]})\n",
    "data_kmeans = data_kmeans.append({'x': data_kmeans['x'].max()*3, 'y':data_kmeans['y'].max()*3}, ignore_index=True)\n",
    "\n",
    "k_cluster = 5 # number of centroids\n",
    "i_iter = 4\n",
    "np.random.seed(21)\n",
    "centroids = init_centroid(data_kmeans, k_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c7a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cluster the same datasets as above, write loop manually, visualise every iteration\n",
    "\n",
    "# Plot init\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(data_kmeans['x'], data_kmeans['y'], c='grey', s=50)\n",
    "plt.scatter([a[0] for a in centroids], [a[1] for a in centroids], c='red', s=200)\n",
    "plt.title(\"Initialization\", fontsize=45)\n",
    "plt.show()\n",
    "\n",
    "for i in range(i_iter):\n",
    "    \n",
    "    print(len(centroids))\n",
    "    \n",
    "    # Compute nearest centroid\n",
    "    data_kmeans['centroid'] = data_kmeans.apply(lambda u: get_centroid(centroids, u['x'], u['y']), axis=1)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data_kmeans['x'], data_kmeans['y'], c=data_kmeans['centroid'], s=50, cmap='viridis')\n",
    "    plt.scatter([a[0] for a in centroids], [a[1] for a in centroids], c='red', s=200)\n",
    "    plt.title(\"Iteration \" + str(i+1) + \": find centroids\", fontsize=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Adjust centroids\n",
    "    centroids = data_kmeans.groupby('centroid').agg(\n",
    "        x=('x', np.mean),\n",
    "        y=('y', np.mean),\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data_kmeans['x'], data_kmeans['y'], c=data_kmeans['centroid'], s=50, cmap='viridis')\n",
    "    plt.scatter(centroids['x'], centroids['y'], c='red', s=200, alpha=0.9)\n",
    "    plt.title(\"Iteration \" + str(i+1) + \": adjust centroids\", fontsize=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save centroids as list\n",
    "    centroids = centroids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef210e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After initialization using uniform distribution there is high probability that we lost some clusters and/or\n",
    "# the outliers are assigned their own cluster.\n",
    "\n",
    "# TODO: Adjust the method 'init_centroid' so that probability that outlier creates their own cluster is low. Observe changes in the algorithm\n",
    "def init_centroid(data, k_cluster):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "centroids = init_centroid(data_kmeans, k_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4df14b",
   "metadata": {},
   "source": [
    "# K-nearest neighbors\n",
    "\n",
    "We inspect prediction algorithm that utilizes the distances between predictors. Namely, given labeled data points and an unlabeled data point, we predict the label using labels of its neighbors. Either fixed number of neighbors is considered or all neighbors within given distance; then some aggregation technique is used to compute the prediction.\n",
    "\n",
    "In our case we predict 0/1-valued TARGET from credit risk dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad9397",
   "metadata": {},
   "source": [
    "### Import data & manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfacb0-4b54-4300-ad55-9bef5d45823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_file = Path(\"../Data/data_devsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18485109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file, sep = ',', encoding = 'utf-8', low_memory=False, index_col='SK_ID_CURR')\n",
    "print(f'data is object of type:   {type(data)}')\n",
    "print(f'Number of rows:      {data.shape[0]}')\n",
    "print(f'Number of columns:   {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df7bd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[['TARGET', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'OCCUPATION_TYPE']]\n",
    "data = data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65f423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We separate continuous and categorical predictors\n",
    "preds_cont = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE']\n",
    "preds_cat = ['OCCUPATION_TYPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b6ce4",
   "metadata": {},
   "source": [
    "The dataset contains continuous and categorical predictors. Therefore, a suitable distance has to be introduced. We measure the distance of vectors $x, y$ as\n",
    "\n",
    "\\begin{align*}\n",
    "dist(x, y)=\\sum_{k\\in Cont}{(x_k-y_k)^2}+\\gamma\\sum_{l\\in Cat}{(1-\\delta_{x_l, y_l})},\n",
    "\\end{align*}\n",
    "for some metaparameter $\\gamma\\geq 0$, where $Cont$ denotes the set of indices containing continuous variables, $Cat$ similarly for categorial ones, $\\delta$ is the delta function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7a9de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing target\n",
    "data = data[data['TARGET'].notna()]\n",
    "\n",
    "# Fill missing values for continuous variables\n",
    "data.fillna((data[preds_cont].mean()), inplace=True)\n",
    "\n",
    "# Fill missing values for categorical variable by placeholder 'MISSING_VALUE'\n",
    "data.fillna('MISSING_VALUE', inplace=True)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ae61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We have to standardize the continuous variables so that distances are comparable among different predictors.\n",
    "data[preds_cont] = StandardScaler().fit_transform(data[preds_cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6cfac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Divide into train and test\n",
    "data_train, data_test = train_test_split(data, test_size=0.1, random_state=17, stratify=data['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44008242",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac936db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_dist(a, b, gamma=1):\n",
    "    \n",
    "    \"\"\"\n",
    "        Computes distance of two data points possibly containing categorical dimensions.\n",
    "        \n",
    "        Args:\n",
    "            - a, b: data points as Series containing dimensions in lists preds_cont and preds_cat\n",
    "            - gamma: parameter that specify distance (see above)\n",
    "            \n",
    "        Returns:\n",
    "            float: distance of a,b\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Continuous dimensions\n",
    "    dist_cont = 0\n",
    "    for pred in preds_cont:\n",
    "        dist_cont = dist_cont + (a[pred]-b[pred])**2\n",
    "    \n",
    "    # Categorical dimensions\n",
    "    dist_cat = 0\n",
    "    for pred in preds_cat:\n",
    "        dist_cat += 1-int(a[pred]!=b[pred])\n",
    "    \n",
    "    return dist_cont + gamma*dist_cat\n",
    "\n",
    "def predict(data, observation, gamma=1, k=50):\n",
    "    \n",
    "    \"\"\"\n",
    "        Computes prediction for one observation given labeled data and criterion how to determine neighborhood.\n",
    "        \n",
    "        Args:\n",
    "            - data: labeled data containing dimensions in lists preds_cont and preds_cat\n",
    "            - observation: unlabeled data point as Series containing dimensions in lists preds_cont and preds_cat\n",
    "            - gamma: parameter specifying distance\n",
    "            - k: number of neighbors to consider\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute distance to every data point from train data\n",
    "    data['DIST'] = data.apply(lambda x: compute_dist(x, observation, gamma), axis=1)\n",
    "    \n",
    "    # Take 'k' closest neighbors\n",
    "    data_neigh = data.sort_values('DIST',ascending = True).head(k)\n",
    "    \n",
    "    # Predict using neighbors\n",
    "    return data_neigh['TARGET'].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c493d7",
   "metadata": {},
   "source": [
    "### Predict using k-nearest observations\n",
    "\n",
    "Now we predict for test data for different values of 'k' and compare performance in terms of AUC.\n",
    "\n",
    "Warning: Takes time even for k=30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07f5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc = {}\n",
    "for k in range(1, 29, 2):\n",
    "\n",
    "    data_test['PREDICTION'] = data_test.apply(lambda x: predict(data_train, x, 2, k), axis=1)\n",
    "    auc[k] =  sklearn.metrics.roc_auc_score(data_test['TARGET'], data_test['PREDICTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(*zip(*auc.items()))\n",
    "plt.title('AUC for K-nearest neighbor model')\n",
    "plt.xlabel('Number of neighbors K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80528a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Adjust the function 'predict' so that parameter 'k' now stands for the radius that determines the neighborhood of given data point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
