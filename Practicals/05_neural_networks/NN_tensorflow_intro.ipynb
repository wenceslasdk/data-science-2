{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but <span style=\"color:red\"> NOT </span> appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:')\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
