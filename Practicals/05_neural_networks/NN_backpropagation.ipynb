{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa8c2ec",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this tutorial we learn how the most basic neural networks work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d850a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd7c84",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb2a55",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "Create toy dataset, define class for weights intialization etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the true weights, use them for data generation later:\n",
    "w_1 = np.array(np.transpose([[2, 1], [1, 0], [1, -1]]))\n",
    "b_1 = np.array(np.expand_dims([1, 0, 2], axis=0))\n",
    "w_2 = np.array([[1,], [1,], [-2,]])\n",
    "b_2 = 1\n",
    "\n",
    "w_1.shape, b_1.shape, w_2.shape\n",
    "\n",
    "# Print the ouput nicely\n",
    "print(\"WEIGHTS OF THE MODEL \\n\")\n",
    "print(\"Hidden layer weights: \\n{} \\n\".format(w_1))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b_1))\n",
    "print(\"Output layer weights: \\n{} \\n\".format(w_2))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782efc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class for initialization of weights - fix seed to use the same numbers always\n",
    "class MyInit(tf.keras.initializers.Initializer):\n",
    "\n",
    "  def __init__(self, mean, std):\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "\n",
    "  def __call__(self, shape, dtype=None, **kwargs):\n",
    "    tf.random.set_seed(11)\n",
    "    return tf.cast(tf.cast(tf.random.normal(\n",
    "        shape, mean=self.mean, stddev=self.std, dtype=dtype), tf.int32), tf.float32)\n",
    "\n",
    "  def get_config(self):  # To support serialization\n",
    "    return {\"mean\": self.mean, \"std\": self.std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define forward propagation\n",
    "def forward_propagation(x, w_1, b_1, w_2, b_2):\n",
    "    h = np.matmul(x, w_1) + b_1\n",
    "    h_relu = np.where(h < 0, 0, h)\n",
    "    y = np.matmul(h_relu, w_2) + b_2\n",
    "    \n",
    "    return {'hidden': h, 'hidden_relu': h_relu, 'prediction': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf83c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data using the true weights\n",
    "np.random.seed(seed=73)\n",
    "x_1 = [-4] + [int(x) for x in np.random.uniform(-2, 4, 100)]\n",
    "x_2 = [1] + [int(x) for x in np.random.uniform(-2, 4, 100)]\n",
    "x = np.transpose(np.array([x_1, x_2]))\n",
    "\n",
    "y = forward_propagation(x, w_1, b_1, w_2, b_2)['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training data to tf.data.Dataset with batch size\n",
    "batch_size = 1\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286a54f",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple NN with the pre-defined intialization:\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "\n",
    "x1 = tf.keras.layers.Dense(3,\n",
    "                           activation=\"relu\",\n",
    "                           name=\"hidden\",\n",
    "                           kernel_initializer=MyInit(1, 1),\n",
    "                           bias_initializer=MyInit(2, 1))(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1,\n",
    "                                name=\"predictions\",\n",
    "                                kernel_initializer=MyInit(1, 3),\n",
    "                                bias_initializer=MyInit(2, 0))(x1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# set the loss and the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cff8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the initialized weights\n",
    "w1 = model.layers[1].weights[0].numpy()\n",
    "b1 = model.layers[1].weights[1].numpy()\n",
    "\n",
    "w2 = model.layers[2].weights[0].numpy()\n",
    "b2 = model.layers[2].weights[1].numpy()\n",
    "\n",
    "# Print the ouput nicely\n",
    "print(\"WEIGHTS OF THE MODEL \\n\")\n",
    "print(\"Hidden layer weights: \\n{} \\n\".format(w1))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b1))\n",
    "print(\"Output layer weights: \\n{} \\n\".format(w2))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5facadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the forward propagation\n",
    "fp = forward_propagation(x[0:1], w1, b1, w2, b2)\n",
    "\n",
    "# Print the ouput nicely\n",
    "print(\"PROPAGATED VALUES \\n\")\n",
    "print(\"Input vector \\n{} \\n\".format(x[0]))\n",
    "print(\"Hidden layer before activation \\n{} \\n\".format(fp[\"hidden\"]))\n",
    "print(\"Hidden layer after relu \\n{} \\n\".format(fp[\"hidden_relu\"]))\n",
    "print(\"Prediction of output layer \\n{} \\n\".format(fp[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first batch\n",
    "for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    break\n",
    "\n",
    "x_batch_train.numpy(), y_batch_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe005d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the gradients on the batch:\n",
    "with tf.GradientTape() as tape:\n",
    "    prediction = model(x_batch_train, training=True)\n",
    "    loss_value = loss_fn(y_batch_train, prediction)\n",
    "\n",
    "\n",
    "grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "# Print the ouput nicely\n",
    "print(\"Prediction:{}, Target:{}, Loss:{}\".format(prediction, y[0], loss_value))\n",
    "print(\"\\n>>> GRADIENTS:\")\n",
    "print(\"Hidden layer weights \\n{} \\n\".format(grads[0].numpy()))\n",
    "print(\"Hidden layer bias \\n{} \\n\".format(grads[1].numpy()))\n",
    "print(\"Output layer weights \\n{} \\n\".format(grads[2].numpy()))\n",
    "print(\"Output layer bias \\n{} \\n\".format(grads[3].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94821ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply one SGD update\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the weights after the update:\n",
    "w1 = model.layers[1].weights[0].numpy()\n",
    "b1 = model.layers[1].weights[1].numpy()\n",
    "\n",
    "w2 = model.layers[2].weights[0].numpy()\n",
    "b2 = model.layers[2].weights[1].numpy()\n",
    "\n",
    "# Print the ouput nicely\n",
    "print(\"UPDATED WEIGHTS OF THE MODEL \\n\")\n",
    "print(\"Hidden layer weights: \\n{} \\n\".format(w1))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b1))\n",
    "print(\"Output layer weights: \\n{} \\n\".format(w2))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the prediction\n",
    "prediction = model(x_batch_train, training=True)\n",
    "loss_value = loss_fn(y_batch_train, prediction)\n",
    "\n",
    "print(\"Prediction:{}, Target:{}, Loss:{}\".format(prediction, y[0], loss_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ab5fd",
   "metadata": {},
   "source": [
    "### Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b51dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pred = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, pred)\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        mse = np.mean((model(x).numpy() - y)**2)\n",
    "        \n",
    "    print('>>> Loss {:.3f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = model.layers[1].weights[0].numpy()\n",
    "b1 = model.layers[1].weights[1].numpy()\n",
    "\n",
    "w2 = model.layers[2].weights[0].numpy()\n",
    "b2 = model.layers[2].weights[1].numpy()\n",
    "\n",
    "print(\"Hidden layer weights: \\n{} \\n\".format(w1))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b1))\n",
    "print(\"Output layer weights: \\n{} \\n\".format(w2))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((model(x).numpy() - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecf166",
   "metadata": {},
   "source": [
    "### Playing with optimizer and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf849e00",
   "metadata": {},
   "source": [
    "http://2.bp.blogspot.com/-q6l20Vs4P_w/VPmIC7sEhnI/AAAAAAAACC4/g3UOUX2r_yA/s400/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b120d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "\n",
    "x1 = tf.keras.layers.Dense(3,\n",
    "                           activation=\"relu\",\n",
    "                           name=\"hidden\",\n",
    "                           kernel_initializer=MyInit(1, 1),\n",
    "                           bias_initializer=MyInit(2, 1))(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1,\n",
    "                                name=\"predictions\",\n",
    "                                kernel_initializer=MyInit(1, 3),\n",
    "                                bias_initializer=MyInit(2, 0))(x1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3376f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "epochs = 128\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pred = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, pred)\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        mse = np.mean((model(x).numpy() - y)**2)\n",
    "        \n",
    "    print('>>> Loss {:.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1840b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w1 = model.layers[1].weights[0].numpy()\n",
    "b1 = model.layers[1].weights[1].numpy()\n",
    "\n",
    "w2 = model.layers[2].weights[0].numpy()\n",
    "b2 = model.layers[2].weights[1].numpy()\n",
    "\n",
    "print(\"Hidden layer weights: \\n{} \\n\".format(w1))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b1))\n",
    "print(\"Output layer weights: \\n{} \\n\".format(w2))\n",
    "print(\"Hidden layer bias: \\n{} \\n\".format(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc2dd3",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Try different optimizers with different lerning rate, how does the convergence look? Does it converge? How fast? Which one is the best?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21448740",
   "metadata": {},
   "source": [
    "## Vanishing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4dc66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a simple NN with the pre-defined intialization:\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=2, name=\"input_values\")\n",
    "\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\")(inputs)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(3, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# set the loss and the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.MSE\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first batch\n",
    "for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    break\n",
    "\n",
    "x_batch_train.numpy(), y_batch_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradients on the batch:\n",
    "with tf.GradientTape() as tape:\n",
    "    prediction = model(x_batch_train, training=True)\n",
    "    loss_value = loss_fn(y_batch_train, prediction)\n",
    "\n",
    "grads = tape.gradient(loss_value, model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90cabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the ouput nicely\n",
    "print(\"Prediction:{}, Target:{}, Loss:{}\".format(prediction, y[0], loss_value))\n",
    "print(\"\\n>>> GRADIENTS:\")\n",
    "\n",
    "for i in range(0, 18, 2):\n",
    "    l = int(i / 2 + 1)\n",
    "    print('-' * 100)\n",
    "    print(\"# {} layer weights \\n{} \\n\".format(l, grads[i].numpy()))\n",
    "    print(\"# {} layer bias \\n{} \\n\".format(l, grads[i+1].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5086a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pred = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, pred)\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        mse = np.mean((model(x).numpy() - y)**2)\n",
    "        \n",
    "    print('>>> Loss {:.3f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9787e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the gradients after some time of training\n",
    "print(\"Prediction:{}, Target:{}, Loss:{}\".format(prediction, y[0], loss_value))\n",
    "print(\"\\n>>> GRADIENTS:\")\n",
    "\n",
    "for i in range(0, 18, 2):\n",
    "    l = int(i / 2 + 1)\n",
    "    print('-' * 100)\n",
    "    print(\"# {} layer weights \\n{} \\n\".format(l, grads[i].numpy()))\n",
    "    print(\"# {} layer bias \\n{} \\n\".format(l, grads[i+1].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b544c1d",
   "metadata": {},
   "source": [
    "## Two circles example\n",
    "see https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca57c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=1000, noise=0.1, random_state=1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f145b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    samples_ix = np.where(y == i)\n",
    "    pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model run for various model specifications\n",
    "def run(model, iterations):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    for r in range(iterations):\n",
    "        print(\"After {} episodes:\".format((r + 1)* 10))\n",
    "        history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=10, batch_size=100, verbose=0)\n",
    "        acc_train.extend(history.history['accuracy'])\n",
    "        acc_test.extend(history.history['val_accuracy'])\n",
    "\n",
    "        prediction = model.predict(trainX)\n",
    "        prediction = np.where(model.predict(trainX) > 0.5, 1, 0)\n",
    "\n",
    "        for i in range(2):\n",
    "            samples_ix = np.where(prediction == i)\n",
    "            pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "\n",
    "    pyplot.plot(acc_train, label='train')\n",
    "    pyplot.plot(acc_test, label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    \n",
    "    print('Evaluation')\n",
    "    model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d988648",
   "metadata": {},
   "source": [
    "### Models with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847945b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(2, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc05f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "acc_train = []\n",
    "acc_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b040bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065df85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcff372",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec06ff",
   "metadata": {},
   "source": [
    "### Models with tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4b63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(2, activation=\"tanh\", kernel_initializer=init)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3b621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(10, activation=\"tanh\", kernel_initializer=init)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34c213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd4426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"tanh\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1dc32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the gradients\n",
    "with tf.GradientTape() as tape:\n",
    "    prediction = model(trainX, training=True)\n",
    "    loss_value = loss_fn(testy, prediction)\n",
    "\n",
    "grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "print(\"\\n>>> GRADIENTS:\")\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    l = int((i + 1) / 2)\n",
    "    print('-' * 100)\n",
    "    print(\"# {} layer weights \\n{} \\n\".format(l, grads[i].numpy()))\n",
    "    print(\"# {} layer bias \\n{} \\n\".format(l, grads[i+1].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11fdeb",
   "metadata": {},
   "source": [
    "### Models without activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef945286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=None, kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=None, kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=None, kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=None, kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=None, kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(1)(h)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb490f9b",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Similar to the accuracy, store and plot also the train and test loss. Inspect the loss evolution.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b43e8d",
   "metadata": {},
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb087dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_classes=4, random_state=1, n_clusters_per_class=1,\n",
    "                           class_sep=2)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "for i in range(4):\n",
    "    samples_ix = np.where(y == i)\n",
    "    pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a23d753",
   "metadata": {},
   "source": [
    "#### ReLU models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a7ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model run for various model specifications\n",
    "def run(model):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    for r in range(20):\n",
    "        print(\"After {} episodes:\".format((r + 1)* 10))\n",
    "        history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=10, verbose=0)\n",
    "        acc_train.extend(history.history['sparse_categorical_accuracy'])\n",
    "        acc_test.extend(history.history['val_sparse_categorical_accuracy'])\n",
    "\n",
    "        prediction = model.predict(trainX)\n",
    "        prediction = np.argmax(model.predict(trainX), axis=1)\n",
    "\n",
    "        for i in range(4):\n",
    "            samples_ix = np.where(prediction == i)\n",
    "            pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "\n",
    "    pyplot.plot(acc_train, label='train')\n",
    "    pyplot.plot(acc_test, label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    print('Evaluation')\n",
    "    model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710a0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf150ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13be908",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(h)\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb669198",
   "metadata": {},
   "source": [
    "### Complex multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66727bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model run for various model specifications\n",
    "def run(model):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    for r in range(20):\n",
    "        print(\"After {} episodes:\".format((r + 1)* 10))\n",
    "        history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=10, verbose=0)\n",
    "        acc_train.extend(history.history['sparse_categorical_accuracy'])\n",
    "        acc_test.extend(history.history['val_sparse_categorical_accuracy'])\n",
    "\n",
    "        prediction = model.predict(trainX)\n",
    "        prediction = np.argmax(model.predict(trainX), axis=1)\n",
    "\n",
    "        for i in range(4):\n",
    "            samples_ix = np.where(prediction == i)\n",
    "            pyplot.scatter(trainX[samples_ix, 0], trainX[samples_ix, 1], label=str(i))\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "\n",
    "    pyplot.plot(acc_train, label='train')\n",
    "    pyplot.plot(acc_test, label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    print('Evaluation')\n",
    "    model.evaluate(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc612a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X_1, y_1 = make_moons(n_samples=1000, random_state=42, noise=0.2)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_1 = scaler.fit_transform(X_1)\n",
    "\n",
    "X_2, y_2 = make_moons(n_samples=1000, random_state=42, noise=0.2)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_2 = scaler.fit_transform(X_1)\n",
    "\n",
    "X = np.append(X_1, X_2 * np.array([1.2, 0.8]) + np.array([-1, -1]), axis=0)\n",
    "y = np.append(y_1, y_2 + 2, axis=0)\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, random_state=3)\n",
    "\n",
    "for i in range(4):\n",
    "    samples_ix = np.where(y == i)\n",
    "    pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea73ba",
   "metadata": {},
   "source": [
    "#### Model with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177d8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bd871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2bd51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "init = tf.keras.initializers.RandomUniform(minval=0, maxval=1)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2,), name=\"input_values\")\n",
    "h = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "h = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=init)(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(4)(h)\n",
    "outputs = tf.keras.activations.softmax(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(model, iterations):\n",
    "#     optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "#     loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "#     acc_train = []\n",
    "#     acc_test = []\n",
    "#     loss_train = []\n",
    "#     loss_test = []\n",
    "\n",
    "#     for r in range(iterations):\n",
    "#         print(\"After {} episodes:\".format((r + 1) * 10))\n",
    "#         history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=10, batch_size=100, verbose=0)\n",
    "#         acc_train.extend(history.history['accuracy'])\n",
    "#         acc_test.extend(history.history['val_accuracy'])\n",
    "#         loss_train.extend(history.history['loss'])\n",
    "#         loss_test.extend(history.history['val_loss'])\n",
    "\n",
    "#         prediction = model.predict(trainX)\n",
    "#         prediction = np.where(model.predict(trainX) > 0.5, 1, 0)\n",
    "\n",
    "#         for i in range(2):\n",
    "#             samples_ix = np.where(prediction == i)\n",
    "#             pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
    "#         pyplot.legend()\n",
    "#         pyplot.show()\n",
    "\n",
    "#     pyplot.plot(acc_train, label='train')\n",
    "#     pyplot.plot(acc_test, label='test')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()\n",
    "\n",
    "#     pyplot.plot(loss_train, label='train')\n",
    "#     pyplot.plot(loss_test, label='test')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()\n",
    "\n",
    "#     print('Evaluation')\n",
    "#     model.evaluate(testX, testy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
