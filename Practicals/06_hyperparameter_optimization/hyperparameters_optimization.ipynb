{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af8e560",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "- this notebook shows basic libraries and procedures used for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acecc026",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "f87ed611",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "782bd4ac",
   "metadata": {},
   "source": "RANDOM_STATE = 12",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e8e8cf9",
   "metadata": {},
   "source": [
    "# Create dataset for binary classification\n",
    "- function `make_classification` from sklearn.datasets allows to create dataset for multiclass classification problem. Inside several features are predictive, some features can be correlated and some features are uninformative with respect to target.\n",
    "- through function parameters we can control number of predictive features, number of target classes and other characteristics of the sample"
   ]
  },
  {
   "cell_type": "code",
   "id": "73ffb06e",
   "metadata": {},
   "source": "from sklearn.datasets import make_classification",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd2c36d7",
   "metadata": {},
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100000, \n",
    "    n_features=15, \n",
    "    n_informative=2, \n",
    "    n_redundant=2, \n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    flip_y=0.1,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Split sample\n",
    "\n",
    "It is recommended to use stratification."
   ],
   "id": "5f2f3cfbd3aa87ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "61c8ab88da7777fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")"
   ],
   "id": "ac485cf5c6a889b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "82fd4979",
   "metadata": {},
   "source": [
    "# Hyper-parameters optimization\n",
    "Hyper-parameters are parameters not directly learned by estimator. They must be passed to the estimator as its parameters.\n",
    "\n",
    "Search consists of:\n",
    "- estimator\n",
    "- parameter search space\n",
    "- method for searching the space\n",
    "- score function\n",
    "\n",
    "Basic approaches for optimal hyper-parameters selection:\n",
    "    \n",
    "    1. Grid search\n",
    "    2. Randomized grid search\n",
    "    3. Grid search with halving\n",
    "    4. Randomized grid search with halving\n",
    "    \n",
    "**Cross validation** is usually used during hyper-parameters optimization process."
   ]
  },
  {
   "cell_type": "code",
   "id": "da1d8c1e",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6fc15cf7",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "Perfoms exhaustive grid search - every combination from search space is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "id": "26803309",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dad1385e",
   "metadata": {},
   "source": [
    "params_grid = [\n",
    "    {'max_depth': [2, 4, 8, 16], 'criterion': ['gini', 'entropy']},\n",
    "#     {'min_samples_split': [100, 1000, 10000], 'ccp_alpha': [0.0, 0.0001, 0.00025]},\n",
    "]\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=tree, \n",
    "    param_grid=params_grid, \n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    error_score=0,\n",
    "    refit=False\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4220aab",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6348e05f",
   "metadata": {},
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ccc5d2f",
   "metadata": {},
   "source": [
    "param = 'criterion'\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "other_pars = []\n",
    "i = 0\n",
    "for pars in clf.cv_results_['params']:\n",
    "    if param in pars:\n",
    "        x.append(pars[param] or -999)\n",
    "        y.append(clf.cv_results_['mean_test_score'][i])\n",
    "        other_pars.append(', '.join([f'{p}:{v}' for p, v in pars.items() if p != param]))\n",
    "        i += 1\n",
    "\n",
    "encoding = {}\n",
    "j = 1\n",
    "for i in np.unique(x):\n",
    "    encoding[i] = j\n",
    "    j += 1\n",
    "    \n",
    "xe = [encoding[i] for i in x]\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "for i in range(len(x)):\n",
    "    ax.scatter(xe[i], y[i], label=other_pars[i])\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1.02))\n",
    "ax.set_xticks(xe)\n",
    "ax.set_xticklabels(x, rotation = 90, color='gray')\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel('auc')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "211cfe77",
   "metadata": {},
   "source": [
    "## Randomized grid search\n",
    "Parameter value is selected from a distribution of possible values.\n",
    "\n",
    "- Number of evaluated combinations can be restricted independently on number of parameters and their possible values.\n",
    "- Parameters with low impact do not decrease efficiency."
   ]
  },
  {
   "cell_type": "code",
   "id": "d468c803",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import expon"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5009fc11",
   "metadata": {},
   "source": [
    "params_dist = [\n",
    "#     {'max_depth': [2, 3, 4, None], 'criterion': ['gini', 'entropy']},\n",
    "    {'min_samples_split': np.unique(np.logspace(1, 4, num=30, dtype=int)), 'ccp_alpha': expon(scale=0.00025)},\n",
    "]\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=8)\n",
    "\n",
    "# Budget is controlled through parameter n_iter\n",
    "clf = RandomizedSearchCV(\n",
    "    estimator=tree, \n",
    "    param_distributions=params_dist, \n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_iter = 8,\n",
    "    error_score=0,\n",
    "    refit=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a6bd7a7",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a661737",
   "metadata": {},
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.DataFrame(clf.cv_results_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e43d020",
   "metadata": {},
   "source": [
    "param = 'min_samples_split'\n",
    "metric = 'roc_auc'\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "other_pars = []\n",
    "i = 0\n",
    "for pars in clf.cv_results_['params']:\n",
    "    if param in pars:\n",
    "        x.append(pars[param] or -999)\n",
    "        y.append(clf.cv_results_[f'mean_test_score'][i])\n",
    "        other_pars.append(', '.join([f'{p}:{v:.2E}' if p=='ccp_alpha' else f'{p}:{v}' for p, v in pars.items() if p != param]))\n",
    "        i += 1\n",
    "\n",
    "encoding = {}\n",
    "j = 1\n",
    "for i in np.unique(x):\n",
    "    encoding[i] = j\n",
    "    j += 1\n",
    "    \n",
    "xe = [encoding[i] for i in x]\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "for i in range(len(x)):\n",
    "    ax.scatter(xe[i], y[i], label=other_pars[i])\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1.02))\n",
    "ax.set_xticks(xe)\n",
    "ax.set_xticklabels(x, rotation = 90, color='gray')\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel(metric)\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4b52865",
   "metadata": {},
   "source": [
    "## Randomized grid search with halving\n",
    "Halving allows to optimize resources allocation for optimization process. First, lot of parameters combinations are evaluated using small amount of resources. In next iteration only combinations with biggest potential are considered and evaluated again with more resources.\n",
    "\n",
    "Important parametres of halving process:\n",
    "- resource: Resource to be increased in each iteration. By default resource is number of observations to be used for cross validation. But it can be for instance number of trees to be used in random forest classifier.\n",
    "- n_candidates: Number of parameters combinations to be evaluated in first iteration.\n",
    "- min_resources: Amount of resources to be used in first iteration.\n",
    "- factor: In each iteration resources are multiplied by factor and number of candidetes is divided by factor. If factor = 2 and iteration i uses 1000 observation, then iteration i+1 will use i\\*factor = 2000 observations. Number of candidetes in i+t-th iteration is number of candidates in i-th iteration divided by factor (and with decimal part removed)."
   ]
  },
  {
   "cell_type": "code",
   "id": "69a94e18",
   "metadata": {},
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import expon"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3401118",
   "metadata": {},
   "source": [
    "params_dist = [\n",
    "    {\n",
    "        'max_depth': [2, 4, 8, 16], \n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': np.unique(np.logspace(1, 4, num=30, dtype=int)), \n",
    "        'ccp_alpha': expon(scale=0.00025)\n",
    "    }\n",
    "]\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "clf = HalvingRandomSearchCV(\n",
    "    estimator=tree,\n",
    "    param_distributions=params_dist,\n",
    "    n_candidates=50,\n",
    "    factor=2,\n",
    "    resource='n_samples',\n",
    "    min_resources='exhaust',\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    error_score=0,\n",
    "    refit=False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32844050",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e6fa97d",
   "metadata": {},
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e37aa5ae",
   "metadata": {},
   "source": [
    "cvres = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "cvres.groupby('iter')['iter'].count()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a88e3f06",
   "metadata": {},
   "source": [
    "cvres = pd.DataFrame(clf.cv_results_)\n",
    "param_combs = cvres[cvres['iter'] == 3]['params'].to_list()\n",
    "\n",
    "cvres_res = pd.DataFrame()\n",
    "ax = plt.subplot(1,1,1)\n",
    "for pc in param_combs:\n",
    "    dt = cvres[cvres['params'] == pc]\n",
    "    label = ', '.join([f'{p}:{v:.2E}' if p=='ccp_alpha' else f'{p}:{v}' for p,v in pc.items()])\n",
    "    ax.plot(dt['iter'], dt['mean_test_score'], marker='o', label=label)\n",
    "\n",
    "ax.set_xticks(dt['iter'])\n",
    "ax.set_xticklabels(\n",
    "    cvres[['iter', 'n_resources']].drop_duplicates().apply(lambda row: f'iter: {row[0]}\\n resources: {row[1]}', axis = 1).to_list(), \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.05, 1.02))\n",
    "ax.set_ylabel(metric)\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d13ebe02",
   "metadata": {},
   "source": [
    "## Searching hyperparameters in pipeline "
   ]
  },
  {
   "cell_type": "code",
   "id": "5c14f6f1",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f56171e8",
   "metadata": {},
   "source": [
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectKBest()),\n",
    "    ('model', tree)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'select__k': [5, 10, 15],\n",
    "    'model__max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=3).fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7cba9d96",
   "metadata": {},
   "source": [
    "search.best_params_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec334ad9",
   "metadata": {},
   "source": [
    "dt = pd.DataFrame(search.cv_results_)\n",
    "dt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35046eab",
   "metadata": {},
   "source": [
    "# setup the figure and axes\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "_x = [2, 4, 6, 8]\n",
    "_y = [5, 10, 15]\n",
    "_yy, _xx = np.meshgrid(_y, _x)\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "\n",
    "top = dt['mean_test_score']-0.88\n",
    "bottom = np.zeros_like(top)+0.88\n",
    "width = 2\n",
    "depth = 5\n",
    "\n",
    "ax1.bar3d(x, y, bottom, width, depth, top, shade=True)\n",
    "\n",
    "ax1.set_xlabel('max_depth')\n",
    "ax1.set_ylabel('k_best')\n",
    "ax1.set_zlabel('auc')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01a6196f",
   "metadata": {},
   "source": [
    "## Hyperopt\n",
    "Hyperopt is a library for serial and parallel optimization. Uses Bayesian Optimization principles.\n",
    "\n",
    "To use hyperopt we need to describe:\n",
    "1. The objective function to minimize\n",
    "2. Search space\n",
    "3. Database to be used for storing results \n",
    "4. Search algorithm\n",
    "\n",
    "Unfortunately, documentation is poor for hyperopt library. Some detils may be found at <a href=\"https://github.com/hyperopt/hyperopt/wiki/FMin\" target=\"_top\">hyperopt tutorial</a>."
   ]
  },
  {
   "cell_type": "code",
   "id": "bbc00445",
   "metadata": {},
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "258e932f",
   "metadata": {},
   "source": [
    "# function to be minimized\n",
    "def objective(params):\n",
    "    tree = DecisionTreeClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_depth=params['max_depth'],\n",
    "        ccp_alpha=params['ccp_alpha']\n",
    "    )\n",
    "    scores = cross_val_score(estimator=tree, X=X_train, y=y_train, cv=3, n_jobs=4, scoring='roc_auc')\n",
    "    \n",
    "    return {\n",
    "        'status': STATUS_OK,\n",
    "        'loss': -np.mean(scores),\n",
    "        'std_score': np.std(scores)\n",
    "    }\n",
    "\n",
    "# database for storing results\n",
    "trials = Trials()\n",
    "\n",
    "# space to be searched\n",
    "search_space = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(1, 8, dtype=int)),\n",
    "    'ccp_alpha': hp.uniform('ccp_alpha', 0.0, 0.00025)\n",
    "}\n",
    "\n",
    "# actual minimization\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "#     algo=tpe.rand.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(RANDOM_STATE)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fc53cf9",
   "metadata": {},
   "source": [
    "best"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eedef5f7",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "md = []\n",
    "alpha = []\n",
    "for tr in trials.trials:\n",
    "    md.append(tr['misc']['vals']['max_depth'][0])\n",
    "    alpha.append(tr['misc']['vals']['ccp_alpha'][0])\n",
    "    \n",
    "dt = pd.DataFrame(zip(md, alpha), columns=['max_depth', 'ccp_alpha'])\n",
    "\n",
    "# plt.scatter(best['max_depth'], best['ccp_alpha'], marker='x', color='red')\n",
    "p = sns.jointplot(data=dt, x=\"max_depth\", y=\"ccp_alpha\", kind='kde')\n",
    "p.ax_joint.scatter(best['max_depth'], best['ccp_alpha'], marker='x', color='red', s=100)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1807b355",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(11,5))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(dt.index, dt['max_depth'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('max_depth')\n",
    "plt.plot(dt.index, dt['max_depth'].rolling(window=7).mean(), ls='--', color='black', lw=2)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dt.index, dt['ccp_alpha'])\n",
    "plt.plot(dt.index, dt['ccp_alpha'].rolling(window=7).mean(), ls='--', color='black', lw=2)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('ccp_alpha')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "adb82cac",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "9773a2f0",
   "metadata": {},
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c22089fb",
   "metadata": {},
   "source": [
    "res = []\n",
    "\n",
    "def objective(params, X, y):\n",
    "    ccp_alpha, max_depth = params\n",
    "    max_depth = round(max_depth)\n",
    "    \n",
    "    tree = DecisionTreeClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_depth=max_depth, \n",
    "        ccp_alpha=ccp_alpha\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(estimator=tree, X=X, y=y, cv=3, n_jobs=4, scoring='roc_auc')\n",
    "    print(f'ccp_alpha: {ccp_alpha:.7f};   max_depth: {max_depth};   mean score: {np.mean(scores):.5f}')\n",
    "    res.append((ccp_alpha, max_depth, np.mean(scores)))\n",
    "    return -np.mean(scores)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "029897e6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ccpalpha_bound = (0.0001, 0.00025)\n",
    "maxdepth_bound = (1, 8)\n",
    "\n",
    "boundaries = [ccpalpha_bound, maxdepth_bound]\n",
    "solver = differential_evolution(\n",
    "    objective,\n",
    "    boundaries,\n",
    "    args=(X_train, y_train),\n",
    "    strategy='best1bin',\n",
    "    maxiter=2,\n",
    "    popsize=15,\n",
    "    mutation=0.5,\n",
    "    recombination=0.7,\n",
    "    tol=0.01,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d1dfcbf",
   "metadata": {},
   "source": [
    "print('Best parameters:')\n",
    "print('----------------')\n",
    "print(f'ccp_alpha:   {solver.x[0]}')\n",
    "print(f'max_depth:   {round(solver.x[1])}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00c7abfa",
   "metadata": {},
   "source": [
    "res = pd.DataFrame(res, columns=['ccp_alpha', 'max_depth', 'mean_score'])\n",
    "\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(res['max_depth'], color='blue')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(res['ccp_alpha'], color='red')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee1d1237",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Optimize hyperparameters for an xgboost model. Define which parameters to optimize and compare multiple methods</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cacc6",
   "metadata": {},
   "source": [
    "# Hyper-parameters optimization with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc41c6f",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e28d244",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "344aa385",
   "metadata": {},
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed_all(seed)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(RANDOM_STATE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1676c636",
   "metadata": {},
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context  # disable certification (needed on mac os)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # converts to [0,1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1aa9522",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = train_dataset[i]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_layers=2, neurons=32, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        acts = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid()\n",
    "        }\n",
    "\n",
    "        layers = [nn.Flatten()]\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(28*28 if len(layers)==1 else neurons, neurons))\n",
    "            layers.append(acts[activation])\n",
    "\n",
    "        layers.append(nn.Linear(neurons, 10))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "de369fd53409c152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate(model, loader):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ],
   "id": "109422bacdfb6516",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer_name=\"Adam\", epochs=2):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizers = {\n",
    "        \"Adam\": optim.Adam,\n",
    "        \"RMSprop\": optim.RMSprop,\n",
    "        \"SGD\": optim.SGD,\n",
    "        \"Adagrad\": optim.Adagrad\n",
    "    }\n",
    "\n",
    "    optimizer = optimizers[optimizer_name](model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1} | Loss {total_loss:.3f} | Val Acc {val_acc:.3f}\")\n",
    "\n",
    "    return val_acc"
   ],
   "id": "97aeb6218ce1242e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizers = [\"Adam\", \"RMSprop\", \"SGD\", \"Adagrad\"]\n",
    "\n",
    "best = 0\n",
    "best_opt = None\n",
    "\n",
    "for opt in optimizers:\n",
    "    print(\"\\nTesting optimizer:\", opt)\n",
    "    model = MLP()\n",
    "    acc = train_model(model, train_loader, val_loader, optimizer_name=opt, epochs=2)\n",
    "\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        best_opt = opt\n",
    "\n",
    "print(\"Best optimizer:\", best_opt)"
   ],
   "id": "8a579c9d4f25c957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    \"activation\": [\"relu\", \"sigmoid\"],\n",
    "    \"neurons\": [25],\n",
    "    \"n_layers\": [3]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"\\nTesting:\", params)\n",
    "\n",
    "    model = MLP(\n",
    "        n_layers=params[\"n_layers\"],\n",
    "        neurons=params[\"neurons\"],\n",
    "        activation=params[\"activation\"]\n",
    "    )\n",
    "\n",
    "    score = train_model(model, train_loader, val_loader, epochs=2)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest params:\", best_params)"
   ],
   "id": "1a8f789b7b9fa3b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    \"activation\": [\"relu\", \"sigmoid\"],\n",
    "    \"neurons\": [25],\n",
    "    \"n_layers\": [3]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"\\nTesting:\", params)\n",
    "\n",
    "    model = MLP(\n",
    "        n_layers=params[\"n_layers\"],\n",
    "        neurons=params[\"neurons\"],\n",
    "        activation=params[\"activation\"]\n",
    "    )\n",
    "\n",
    "    score = train_model(model, train_loader, val_loader, epochs=2)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest params:\", best_params)"
   ],
   "id": "f8c515ce6937389b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1c3c9c8b3f707e87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.078px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
