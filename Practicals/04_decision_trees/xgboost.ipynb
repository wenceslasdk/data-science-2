{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "In this tutorial we learn how to process data, train an XGBoost model and validate any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:45.928517Z",
     "start_time": "2021-12-04T18:32:23.351767Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:45.975518Z",
     "start_time": "2021-12-04T18:32:45.962519Z"
    }
   },
   "outputs": [],
   "source": [
    "# set width of Jupyter notebook\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "# set some visual properties of displaying pandas DataFrame\n",
    "pd.options.display.max_columns=200\n",
    "pd.options.display.max_rows=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data if needed (and unpack it into the Data folder), we use the same dataset as in the python intro:** <a href=\"https://www2.karlin.mff.cuni.cz/~kozmikk/files/data_devsample.zip\" target=\"_blank\">credit risk data</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "- Data sample represents data used in financial institutions for development of credit risk scoring models.\n",
    "- This data sample was used in Kaggle competition arranged by Home Credit Group in 2018.\n",
    "- Data includes binary target variable `TARGET` and multiple regressors to be used in model.\n",
    "- Column `SK_ID_CURR` is used as unique identifier of credit application and columns `TIME` represents time of the application.\n",
    "- Model should predict solvency of applicants at the time of application for credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:52.816842Z",
     "start_time": "2021-12-04T18:32:51.290202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data - set index column, decimal point, separator\n",
    "data_file = Path(\"../Data/data_devsample.csv\")\n",
    "data = pd.read_csv(data_file, sep = ',', decimal = '.', index_col = 'SK_ID_CURR')\n",
    "\n",
    "# print time of data being loaded - use strftime\n",
    "print(f'Data loaded on:   {datetime.datetime.now().strftime(format=\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:53.100845Z",
     "start_time": "2021-12-04T18:32:52.912844Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:53.227843Z",
     "start_time": "2021-12-04T18:32:53.196844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print some numbers about data sample size\n",
    "print(f'Number of rows:   {data.shape[0]:,}'.replace(',', ' '))\n",
    "print(f'Number of unique indexes:   {data.index.nunique():,}'.replace(',', ' '))\n",
    "print(f'Number of columns:   {data.shape[1]:,}'.replace(',', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:56.027567Z",
     "start_time": "2021-12-04T18:32:56.015537Z"
    }
   },
   "outputs": [],
   "source": [
    "# check values in column TARGET\n",
    "data.TARGET.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:56.282316Z",
     "start_time": "2021-12-04T18:32:56.268314Z"
    }
   },
   "outputs": [],
   "source": [
    "#name of the target column\n",
    "col_target = \"TARGET\"\n",
    "#name of the time column\n",
    "col_time = \"TIME\"\n",
    "\n",
    "#name of the month column\n",
    "col_month = \"MONTH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:56.753865Z",
     "start_time": "2021-12-04T18:32:56.685863Z"
    }
   },
   "outputs": [],
   "source": [
    "# define list of predictors\n",
    "cols_pred = list(data.columns[1:-4])\n",
    "\n",
    "# define list of numerical predictors\n",
    "cols_pred_num = [col for col in cols_pred if data[col].dtype != 'O']\n",
    "# define list of categorical predictors\n",
    "cols_pred_cat = [col for col in cols_pred if data[col].dtype == 'O']\n",
    "\n",
    "print('Numerical predictors:')\n",
    "print('---------------------')\n",
    "print(data[cols_pred_num].dtypes)\n",
    "print()\n",
    "print('Categorical predictors:')\n",
    "print('-----------------------')\n",
    "print(data[cols_pred_cat].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:57.666026Z",
     "start_time": "2021-12-04T18:32:56.943865Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert col_time to date\n",
    "if data[col_time].dtype == 'O':\n",
    "    data[col_time] = data[col_time].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:57.996319Z",
     "start_time": "2021-12-04T18:32:57.976284Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function to plot default rate in time for different samples\n",
    "def default_rate_in_time_per_sample(dt, col_target, col_month, col_sample):\n",
    "    # group by over month and sample\n",
    "    dt_grp = dt.groupby([col_month, col_sample]).agg(\n",
    "        def_rt = (col_target, np.mean)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # pivot sample values to columns\n",
    "    dt_grp_pivot = dt_grp.pivot(index = col_month, columns = col_sample, values = 'def_rt')\n",
    "\n",
    "    # plot default rate in time\n",
    "    lines = plt.plot(range(len(dt_grp_pivot)), dt_grp_pivot, marker = 'o')\n",
    "    plt.xticks(range(len(dt_grp_pivot)), dt_grp_pivot.index, rotation = 90)\n",
    "    # set legend\n",
    "    plt.legend(iter(lines), tuple(dt_grp_pivot.columns), loc='best', bbox_to_anchor=(1.05, 1))\n",
    "    \n",
    "    plt.ylim([0, 0.1])\n",
    "    plt.ylabel('default rate')\n",
    "    plt.xlabel('month')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('gray')\n",
    "    ax.spines['bottom'].set_color('gray')\n",
    "    ax.tick_params(axis='y', colors='gray')\n",
    "    ax.tick_params(axis='x', colors='gray')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:32:59.282027Z",
     "start_time": "2021-12-04T18:32:58.455288Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sample'] = 'default'\n",
    "\n",
    "# define 'hoot' and 'oot' sample\n",
    "data.loc[data[col_month] <= 201701, 'sample'] = 'hoot'\n",
    "data.loc[data[col_month] >= 201911, 'sample'] = 'oot'\n",
    "\n",
    "# define intime mask\n",
    "intime_mask = (data[col_month] > 201701) & (data[col_month] < 201911)\n",
    "# use train_test_split to split the intime into train and rest (don't forget seed); use stratification\n",
    "data_train, data_rest = train_test_split(data[intime_mask], test_size=0.4, random_state = 12, stratify = (data[intime_mask][[col_month, col_target]]))\n",
    "data.loc[data_train.index, 'sample'] = 'train'\n",
    "# use train_test_split to split the rest into valid and test (don't forget seed); use stratification\n",
    "data_valid, data_test = train_test_split(data_rest, test_size=0.5, random_state = 12, stratify = (data_rest[[col_month, col_target]]))\n",
    "data.loc[data_valid.index, 'sample'] = 'valid'\n",
    "data.loc[data_test.index, 'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:00.384779Z",
     "start_time": "2021-12-04T18:32:59.707996Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_rate_in_time_per_sample(data, col_target, col_month, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sample Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:00.890136Z",
     "start_time": "2021-12-04T18:33:00.843614Z"
    }
   },
   "outputs": [],
   "source": [
    "# define sample masks\n",
    "train_mask = (data['sample'] == 'train')\n",
    "valid_mask = (data['sample'] == 'valid') \n",
    "test_mask = (data['sample'] == 'test') \n",
    "oot_mask = (data['sample'] == 'oot')  \n",
    "hoot_mask = (data['sample'] == 'hoot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:01.487177Z",
     "start_time": "2021-12-04T18:33:01.344178Z"
    }
   },
   "outputs": [],
   "source": [
    "# find columns with infinity values\n",
    "cols_with_inf = []\n",
    "for col in cols_pred_num:\n",
    "    if np.any(np.isinf(data[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(f'Column {col} includes infinity values.')\n",
    "\n",
    "# find columns with negative infinity values\n",
    "cols_with_neginf = []\n",
    "for col in cols_pred_num:\n",
    "    if np.any(np.isneginf(data[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(f'Column {col} includes negative infinity values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:02.597235Z",
     "start_time": "2021-12-04T18:33:02.583192Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace infinity values\n",
    "for col in cols_with_inf:\n",
    "    data[col].replace(np.inf, 9999999, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Predictors\n",
    "- Category encoding is defined by:\n",
    "$$ CategoryEncoding = \\frac{f_{categ}\\cdot DR_{category} + \\alpha \\cdot DR}{f_{categ} + \\alpha} $$\n",
    "where $f_{categ}$ is frequency of category to be encoded, $DR_{category}$ default rate in this category and $DR$ is total default rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(dt, predictor, target, alpha = 0.01):\n",
    "    total_cnt = len(dt)\n",
    "    total_dr = np.mean(dt[target])\n",
    "    dt_grp = dt.groupby(predictor).agg(\n",
    "        categ_dr = (target, np.mean),\n",
    "        categ_cnt = (target, len)\n",
    "    )\n",
    "    \n",
    "    dt_grp['categ_freq'] = dt_grp['categ_cnt'] / total_cnt\n",
    "    dt_grp['categ_encoding'] = (dt_grp['categ_freq'] * dt_grp['categ_dr'] + alpha * total_dr) / (dt_grp['categ_freq'] + alpha)\n",
    "    \n",
    "    return dt_grp[['categ_encoding']].to_dict()['categ_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:07.867552Z",
     "start_time": "2021-12-04T18:33:04.603506Z"
    }
   },
   "outputs": [],
   "source": [
    "total_dr = np.mean(data[train_mask][col_target])\n",
    "\n",
    "# encode categorical predictors\n",
    "for pred in tqdm(cols_pred_cat):\n",
    "    if len(data[pred].unique()) < 0:\n",
    "        dummies = pd.get_dummies(\n",
    "            data[pred], \n",
    "            prefix = pred,\n",
    "            prefix_sep = '_',\n",
    "            dummy_na = True if data[pred].isnull().sum() > 0 else False,\n",
    "            drop_first = False\n",
    "        )\n",
    "        \n",
    "        for d in dummies.columns:\n",
    "            if d in data.columns:\n",
    "                del data[d]\n",
    "                \n",
    "        data = data.join(dummies)\n",
    "        \n",
    "        for col in dummies.columns:\n",
    "            if col not in cols_pred:\n",
    "                cols_pred.append(col)\n",
    "        \n",
    "        if pred in cols_pred:\n",
    "            cols_pred.remove(pred)\n",
    "    else:\n",
    "        new_vals = mean_target_encoding(\n",
    "            dt=data[train_mask], \n",
    "            predictor=pred, \n",
    "            target=col_target\n",
    "        )\n",
    "\n",
    "        additional_values = set(data[data[pred].notnull()][pred].unique()) - set(new_vals.keys())\n",
    "        for p in additional_values:\n",
    "            new_vals[p] = total_dr\n",
    "\n",
    "        data['MTE_' + pred] = data[pred].replace(new_vals)\n",
    "        \n",
    "        if 'MTE_' + pred not in cols_pred:\n",
    "            cols_pred.append('MTE_' + pred)\n",
    "        \n",
    "        if pred in cols_pred:\n",
    "            cols_pred.remove(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T07:55:49.334779Z",
     "start_time": "2020-12-02T07:55:49.304770Z"
    }
   },
   "source": [
    "# XGBoost model\n",
    "- XGBoost model is provided in package `xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First XGBoost model\n",
    "- **early stopping:** Model is trained on training sample and we control model performance on evaluation sample (can be valid or test). If the model does not improve after *n* iterations, we stop the training.\n",
    "- Data must be passed to training as *xgb.DMatrix* data type.\n",
    "- Parameter *dtrain* defines data set to be used for training. Parameter evals is used for passing evaluation data sets - eval_metric will be evaluated on those sets in each iteration. Last data set from evals is used for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:14.723939Z",
     "start_time": "2021-12-04T18:33:09.854398Z"
    }
   },
   "outputs": [],
   "source": [
    "# set best parameters to be used in XGBoost\n",
    "params = {    \n",
    "    'max_depth': 4,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['auc'],\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "booster = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]),\n",
    "    num_boost_round = 1000,\n",
    "    evals = (\n",
    "        (xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]), 'train'),\n",
    "        (xgb.DMatrix(data[test_mask][cols_pred], data[test_mask][col_target]), 'test'),\n",
    "        (xgb.DMatrix(data[valid_mask][cols_pred], data[valid_mask][col_target]), 'valid'),        \n",
    "    ),\n",
    "    evals_result = evals_result,\n",
    "    early_stopping_rounds = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:15.781566Z",
     "start_time": "2021-12-04T18:33:15.261322Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = 'auc'\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "total_iteration_count = len(evals_result[list(evals_result.keys())[0]][metric])\n",
    "for sample, vals in evals_result.items():\n",
    "    ax.plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals[metric],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "best_score = booster.best_score\n",
    "best_iteration = booster.best_iteration+1\n",
    "\n",
    "ax.plot([1, total_iteration_count], [best_score, best_score], color='black', ls='--', lw=1)\n",
    "ax.scatter([best_iteration], [best_score], color = 'black')\n",
    "ax.annotate(\n",
    "    '{:d}; {:0.3f}'.format(best_iteration, best_score), \n",
    "    xy = (best_iteration, best_score), \n",
    "    xytext = (best_iteration,best_score+0.005),\n",
    ")\n",
    "ax.set_xlabel('iteration', color='gray')\n",
    "ax.set_ylabel(metric, color='gray')\n",
    "ax.legend(loc='best')\n",
    "ax.set_title(f'Model training - {metric} curves')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray')\n",
    "\n",
    "# plt.savefig('test.svg', format='svg')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:16.553565Z",
     "start_time": "2021-12-04T18:33:16.289569Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_type = 'total_gain'\n",
    "\n",
    "predictor_strength = sorted([(k, v) for k,v in booster.get_score(importance_type = importance_type).items()], key = lambda x: x[1], reverse = True)\n",
    "predictor_strength = pd.DataFrame(predictor_strength, columns = ['predictor', 'strength'])\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "\n",
    "n_strongest = 20\n",
    "plt.barh(range(n_strongest, 0, -1), predictor_strength['strength'].iloc[0:20])\n",
    "plt.yticks(range(n_strongest, 0, -1), predictor_strength['predictor'].iloc[0:20])\n",
    "plt.xlabel(importance_type)\n",
    "plt.title('Predictor importance')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** change the hyperparameters and observe performance and training</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:33:21.582361Z",
     "start_time": "2021-12-04T18:33:17.109690Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booster_sklearn = xgb.XGBClassifier(\n",
    "    booster='gbtree',\n",
    "    objective='binary:logistic',\n",
    "    random_state=12,\n",
    "    verbosity=1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,    \n",
    ")\n",
    "\n",
    "booster_sklearn.fit(\n",
    "    data[train_mask][cols_pred].values, \n",
    "    data[train_mask][col_target].astype(int).values,\n",
    "    eval_set=[\n",
    "        (data[train_mask][cols_pred].values, data[train_mask][col_target].values),\n",
    "        (data[test_mask][cols_pred].values, data[test_mask][col_target].values),\n",
    "        (data[valid_mask][cols_pred].values, data[valid_mask][col_target].values),\n",
    "    ],\n",
    "    verbose=True,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model\n",
    "Before fitting final model, selection of optimal predictors might be considered. A model with similar performance can be fitted using *n* strongest predictors or using all available predictors. Sometime implementation of the predictors into the production might take some time and therefore you prefer to have \"reasonable\" number of predictors in your model. On the contrary, having larger number of predictors might bring better robustness - if one of the predictors would broke, the impact for the model would be lower.\n",
    "\n",
    "For selection of optimal predictors, similar approach as forward (or backward) process can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:37:55.425356Z",
     "start_time": "2021-12-04T18:37:37.863239Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "\n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'exact',\n",
    "\n",
    "    'seed': 12\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 2, shuffle = True, random_state = 12)\n",
    "\n",
    "X = data[cols_pred].values\n",
    "y = data[col_target].values\n",
    "data['cv_score'] = -1\n",
    "cv_res = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    evals_result = {}\n",
    "    booster = xgb.train(\n",
    "        params = params,\n",
    "        dtrain = xgb.DMatrix(X_train, y_train),\n",
    "        num_boost_round = 1000,\n",
    "        evals = (\n",
    "            (xgb.DMatrix(X_train, y_train), 'train'),\n",
    "            (xgb.DMatrix(X_test, y_test), 'test'),\n",
    "        ),\n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 10,\n",
    "        verbose_eval = True\n",
    "    )\n",
    "    \n",
    "    gini_train = 2 * roc_auc_score(y_train, booster.predict(xgb.DMatrix(X_train))) - 1\n",
    "    gini_test  = 2 * roc_auc_score(y_test,  booster.predict(xgb.DMatrix(X_test)))  - 1\n",
    "    best_iteration = booster.best_iteration\n",
    "    \n",
    "    cv_res += [(gini_train, gini_test, best_iteration)]\n",
    "    \n",
    "    data.iloc[test_index, list(data.columns).index('cv_score')] = list(booster.predict(xgb.DMatrix(X_test), iteration_range=(0, booster.best_iteration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:37:55.975440Z",
     "start_time": "2021-12-04T18:37:55.962248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Performance during cross validation\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:37:56.513472Z",
     "start_time": "2021-12-04T18:37:56.482471Z"
    }
   },
   "outputs": [],
   "source": [
    "gini_cv = 2 * roc_auc_score(data[col_target], data['cv_score']) - 1\n",
    "print(f'Cross validation score performance: {gini_cv:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:09.453806Z",
     "start_time": "2021-12-04T18:37:57.013580Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final model\n",
    "params = {    \n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "\n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'exact',\n",
    "\n",
    "    'seed': 12\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "booster = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = xgb.DMatrix(data[cols_pred], data[col_target]),\n",
    "    evals = (\n",
    "        (xgb.DMatrix(data[cols_pred], data[col_target]), 'train'),\n",
    "    ),\n",
    "    num_boost_round = 130,\n",
    "    evals_result = evals_result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:10.400253Z",
     "start_time": "2021-12-04T18:38:10.039214Z"
    }
   },
   "outputs": [],
   "source": [
    "gini_train = 2 * roc_auc_score(data[col_target], booster.predict(xgb.DMatrix(data[cols_pred]))) - 1\n",
    "print(gini_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model using splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:23.657760Z",
     "start_time": "2021-12-04T18:38:14.127639Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final model\n",
    "params = {    \n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "\n",
    "    'eval_metric': ['logloss', 'auc'],\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'exact',\n",
    "\n",
    "    'seed': 12,\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "booster = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]),\n",
    "    num_boost_round = 300,\n",
    "    evals = (\n",
    "        (xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]), 'train'),\n",
    "        (xgb.DMatrix(data[test_mask][cols_pred],  data[test_mask][col_target]), 'test'),\n",
    "        (xgb.DMatrix(data[valid_mask][cols_pred], data[valid_mask][col_target]), 'valid')\n",
    "    ),\n",
    "    evals_result = evals_result,\n",
    "    early_stopping_rounds = 10,\n",
    "    verbose_eval = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:24.590759Z",
     "start_time": "2021-12-04T18:38:24.227791Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = 'logloss'\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize = (12,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "total_iteration_count = len(evals_result[list(evals_result.keys())[0]][metric])\n",
    "for sample, vals in evals_result.items():\n",
    "    axs[0].plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals[metric],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "    \n",
    "for sample, vals in evals_result.items():\n",
    "    axs[1].plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals['auc'],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "best_score = booster.best_score\n",
    "best_iteration = booster.best_iteration+1\n",
    "\n",
    "plt.plot([1, total_iteration_count], [best_score, best_score], color='black', ls='--', lw=1)\n",
    "plt.scatter([best_iteration], [best_score], color = 'black')\n",
    "plt.annotate(\n",
    "    '{:d}; {:0.3f}'.format(best_iteration, best_score), \n",
    "    xy = (best_iteration, best_score), \n",
    "    xytext = (best_iteration,best_score+0.005),\n",
    "#     textcoords = 'offset points'\n",
    ")\n",
    "\n",
    "axs[0].set_xlabel('iteration')\n",
    "axs[0].set_ylabel('logloss')\n",
    "axs[0].set_title(f'logloss curves')\n",
    "\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "axs[0].spines['left'].set_color('gray')\n",
    "axs[0].spines['bottom'].set_color('gray')\n",
    "axs[0].tick_params(axis='y', colors='gray')\n",
    "axs[0].tick_params(axis='x', colors='gray')\n",
    "\n",
    "axs[1].set_xlabel('iteration')\n",
    "axs[1].set_ylabel('auc')\n",
    "axs[1].set_title(f'auc curves')\n",
    "\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "axs[1].spines['left'].set_color('gray')\n",
    "axs[1].spines['bottom'].set_color('gray')\n",
    "axs[1].tick_params(axis='y', colors='gray')\n",
    "axs[1].tick_params(axis='x', colors='gray')\n",
    "\n",
    "plt.legend(loc='upper right',  bbox_to_anchor=(0.8, 0.5, 0.5, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying monotone constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TO DO:** Define function for marginal dependence.</span>\n",
    "\n",
    "Function should have following input parameters:\n",
    "- data ... pd.DataFrame with data to be used for marginal dependence calculation, TARGET is included in this dataframe\n",
    "- predictor ... name of the predictor to be analysed\n",
    "- bins ... number of bins to split the predictor into\n",
    "- col_target ... the TARGET column to compute default date\n",
    "\n",
    "\n",
    "It should output a graph with the default rate for each bin, for example\n",
    "marginal_dependence(data[train_mask], 'EXT_SOURCE_1', 10, col_target) should give something like\n",
    "\n",
    "<img src=\"marginal_dependence.png\" width=400px style=\"float: left\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from marginal_dependence import marginal_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_dependence(data[train_mask], 'EXT_SOURCE_1', 10, col_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:25.902311Z",
     "start_time": "2021-12-04T18:38:25.888308Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_monotone_constraint = [\n",
    "]\n",
    "\n",
    "negative_monotone_constraint = [\n",
    "    'EXT_SOURCE_1',\n",
    "    'EXT_SOURCE_2',\n",
    "    'EXT_SOURCE_3'\n",
    "]\n",
    "\n",
    "constr = []\n",
    "for col in cols_pred:\n",
    "    if col in positive_monotone_constraint:\n",
    "        constr.append('1')\n",
    "    elif col in negative_monotone_constraint:\n",
    "        constr.append('-1')\n",
    "    else:\n",
    "        constr.append('0')\n",
    "\n",
    "constr = '(' + ','.join(constr) + ')'\n",
    "constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:36.076568Z",
     "start_time": "2021-12-04T18:38:26.395130Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final model\n",
    "params = {    \n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'monotone_constraints': constr,\n",
    "    \n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'exact',\n",
    "\n",
    "    'seed': 12\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "booster = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]),\n",
    "    num_boost_round = 1000,\n",
    "    evals = (\n",
    "        (xgb.DMatrix(data[train_mask][cols_pred], data[train_mask][col_target]), 'train'),\n",
    "        (xgb.DMatrix(data[test_mask][cols_pred],  data[test_mask][col_target]), 'test'),\n",
    "        (xgb.DMatrix(data[valid_mask][cols_pred], data[valid_mask][col_target]), 'valid')\n",
    "    ),\n",
    "    evals_result = evals_result,\n",
    "    early_stopping_rounds = 10,\n",
    "    verbose_eval = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:36.847962Z",
     "start_time": "2021-12-04T18:38:36.628944Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = 'auc'\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "total_iteration_count = len(evals_result[list(evals_result.keys())[0]][metric])\n",
    "for sample, vals in evals_result.items():\n",
    "    plt.plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals[metric],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "best_score = booster.best_score\n",
    "best_iteration = booster.best_iteration+1\n",
    "\n",
    "plt.plot([1, total_iteration_count], [best_score, best_score], color='black', ls='--', lw=1)\n",
    "plt.scatter([best_iteration], [best_score], color = 'black')\n",
    "plt.annotate(\n",
    "    '{:d}; {:0.3f}'.format(best_iteration, best_score), \n",
    "    xy = (best_iteration, best_score), \n",
    "    xytext = (best_iteration,best_score+0.005),\n",
    "#     textcoords = 'offset points'\n",
    ")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel(metric)\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'{metric} curves')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:37.610912Z",
     "start_time": "2021-12-04T18:38:37.340911Z"
    }
   },
   "outputs": [],
   "source": [
    "data['predicted_pd'] = booster.predict(xgb.DMatrix(data[cols_pred]), iteration_range=(0,booster.best_iteration))\n",
    "data['predicted_score'] = np.log(data['predicted_pd'] / (1 - data['predicted_pd']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:38:39.685310Z",
     "start_time": "2021-12-04T18:38:38.130233Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# might need python-graphviz == 0.16\n",
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 80,50\n",
    "\n",
    "plot_tree(booster, num_trees = 0)\n",
    "plt.show()\n",
    "\n",
    "rcParams['figure.figsize'] = 5,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:39:03.850516Z",
     "start_time": "2021-12-04T18:39:03.824480Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_score_calibration(dt, col_score, col_target, n_bins = 25):\n",
    "    min_score = dt[col_score].min() - 0.1\n",
    "    max_score = dt[col_score].max() + 0.1\n",
    "    \n",
    "    bins = [round(min_score + i * (max_score - min_score) / n_bins, 2) for i in range(n_bins+1)]\n",
    "    dt = dt.assign(score_bin = pd.cut(dt[col_score], bins = bins, include_lowest = False))\n",
    "    \n",
    "    dt_grp = dt.groupby('score_bin').agg(\n",
    "        bad_cnt = (col_target, sum),\n",
    "        tot_cnt = (col_target, len),\n",
    "        def_rt = (col_target, np.mean),\n",
    "        avg_score = (col_score, np.mean)\n",
    "    )\n",
    "    dt_grp['good_cnt'] = dt_grp['tot_cnt'] - dt_grp['bad_cnt']\n",
    "    dt_grp['bad_cnt_norm'] = dt_grp['bad_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['good_cnt_norm'] = dt_grp['good_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['expected_pd'] = 1 / (1 + np.exp(-dt_grp['avg_score']))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize = (12,4))\n",
    "    fig.suptitle(col_score)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['bad_cnt'], color = 'salmon', label = 'bads')\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['good_cnt'], bottom = dt_grp['bad_cnt'], color = 'lightblue', label = 'goods')\n",
    "    axs[0].set_ylabel('observations count')\n",
    "    axs[0].set_xlabel('score')\n",
    "    axs[0].set_xticks(range(len(dt_grp)))\n",
    "    axs[0].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[0].spines['right'].set_color('gray')\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['left'].set_color('gray')\n",
    "    axs[0].spines['bottom'].set_color('gray')\n",
    "    axs[0].tick_params(axis='y', colors='gray')\n",
    "    axs[0].tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    ax0l = axs[0].twinx()\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['def_rt'], marker = 'o', color = 'red')\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['expected_pd'], color = 'black', ls = '--')\n",
    "    ax0l.set_ylabel('default rate', color = 'red')\n",
    "    \n",
    "    ax0l.spines['right'].set_color('gray')\n",
    "    ax0l.spines['top'].set_visible(False)\n",
    "    ax0l.spines['left'].set_color('gray')\n",
    "    ax0l.spines['bottom'].set_color('gray')\n",
    "    ax0l.tick_params(axis='y', colors='gray')\n",
    "    ax0l.tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['bad_cnt_norm'], color = 'salmon', label = 'bads')\n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['good_cnt_norm'], bottom = dt_grp['bad_cnt_norm'], color = 'lightblue', label = 'goods')\n",
    "    axs[1].set_ylabel('frequency')\n",
    "    axs[1].set_xlabel('score')\n",
    "    axs[1].set_xticks(range(len(dt_grp)))\n",
    "    axs[1].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['left'].set_color('gray')\n",
    "    axs[1].spines['bottom'].set_color('gray')\n",
    "    axs[1].tick_params(axis='y', colors='gray')\n",
    "    axs[1].tick_params(axis='x', colors='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:39:05.577568Z",
     "start_time": "2021-12-04T18:39:04.629363Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_score_calibration(data[valid_mask | test_mask], 'predicted_score', col_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance\n",
    "- Let's have dataset $D$ and model with score (AUC for instance) $s$\n",
    "- For each feature $j$ calculate permutation importance as follows:\n",
    "    - for $k$ in $1,\\ldots,K$:\n",
    "        - shuffle column $j$ in dataset $D$ -> $\\hat{D}_{k,j}$\n",
    "        - compute the score $s_{k,j}$ using $\\hat{D}_{k,j}$\n",
    "    - importance $i_j$ for feature $f_j$ is defined as:\n",
    "$$i_j = s - \\frac{1}{K}\\sum_{k=1}^K s_{k,j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for sklearn, there is a function\n",
    "r = permutation_importance(booster_sklearn, data[test_mask][cols_pred], data[test_mask][col_target], n_repeats=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{cols_pred[i]:<8}    \"\n",
    "              f\"{r.importances_mean[i]:.4f}\"\n",
    "              f\" +/- {r.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:39:11.361192Z",
     "start_time": "2021-12-04T18:39:11.350139Z"
    }
   },
   "outputs": [],
   "source": [
    "def permutation_importance(dt, predictor, target, model, n_iters = 10):\n",
    "    predictors = list(dt.columns)\n",
    "    predictors.remove(target)\n",
    "    \n",
    "    prediction = model.predict(xgb.DMatrix(dt[predictors]), iteration_range=(0,model.best_iteration))\n",
    "    s = roc_auc_score(dt[target], prediction)\n",
    "    \n",
    "    sk = []\n",
    "    for i in range(n_iters):\n",
    "        x = dt[predictor].to_list()\n",
    "        np.random.shuffle(x)\n",
    "        dt[predictor] = x\n",
    "        prediction = model.predict(xgb.DMatrix(dt[predictors]), iteration_range=(0,model.best_iteration))\n",
    "        sk.append(roc_auc_score(dt[target], prediction))\n",
    "    \n",
    "    sk_mean = np.mean(sk)\n",
    "    sk_perc05 = np.percentile(sk, q=5)\n",
    "    sk_perc95 = np.percentile(sk, q=95)\n",
    "    \n",
    "    return s - sk_mean, s - sk_perc05, s - sk_perc95    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:40:37.260050Z",
     "start_time": "2021-12-04T18:40:26.896732Z"
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for pred in tqdm(cols_pred[0:10]):\n",
    "    pi, iqr95, iqr05 = permutation_importance(\n",
    "        dt=data[test_mask][cols_pred + [col_target]], \n",
    "        predictor=pred,\n",
    "        target=col_target,\n",
    "        model=booster,\n",
    "        n_iters=10\n",
    "    )\n",
    "    res.append((pred, pi, iqr05, iqr95))\n",
    "res = pd.DataFrame(res, columns = ['predictor', 'permutation_importance', 'iqr05', 'iqr95'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:12.904940Z",
     "start_time": "2021-12-04T18:50:48.400833Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(predictors):\n",
    "    params={\n",
    "        'eta': 0.2,\n",
    "        'max_depth': 3,\n",
    "\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic' ,\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "\n",
    "        'base_score': 0.08,\n",
    "\n",
    "        'seed': 12\n",
    "    }\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    booster_mc = xgb.train(\n",
    "        params = params,\n",
    "        dtrain = xgb.DMatrix(data[train_mask][predictors], data[train_mask][col_target]),\n",
    "        num_boost_round = 1000,\n",
    "        evals = (\n",
    "            (xgb.DMatrix(data[train_mask][predictors], data[train_mask][col_target]), 'train'),\n",
    "            (xgb.DMatrix(data[test_mask][predictors], data[test_mask][col_target]), 'test'),\n",
    "            (xgb.DMatrix(data[valid_mask][predictors], data[valid_mask][col_target]), 'valid')\n",
    "        ),\n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 20\n",
    "    )\n",
    "    \n",
    "    \n",
    "    prediction = booster_mc.predict(xgb.DMatrix(data[test_mask][predictors]))\n",
    "    return roc_auc_score(data[test_mask][col_target], prediction)\n",
    "\n",
    "prediction = booster.predict(xgb.DMatrix(data[test_mask][cols_pred]), iteration_range=(0,booster.best_iteration))\n",
    "auc_base = roc_auc_score(data[test_mask][col_target], prediction)\n",
    "\n",
    "marginal_contribution = []\n",
    "for pred in tqdm(cols_pred[0:5]):\n",
    "    auc = fit_model(predictors=[p for p in cols_pred if p != pred])\n",
    "    marginal_contribution.append((pred, auc_base - auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:17.293457Z",
     "start_time": "2021-12-04T18:51:17.288425Z"
    }
   },
   "outputs": [],
   "source": [
    "marginal_contribution = sorted(marginal_contribution, key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:18.107528Z",
     "start_time": "2021-12-04T18:51:18.091526Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "marginal_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:19.935601Z",
     "start_time": "2021-12-04T18:51:19.779586Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature_perm_importance = sorted(zip(cols_pred, pi['importances_mean']), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "plt.figure(figsize=(6,10))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.barh(range(len(marginal_contribution)), [imp for p, imp in marginal_contribution])\n",
    "ax.set_yticks(range(len(marginal_contribution)))\n",
    "ax.set_yticklabels([p for p, imp in marginal_contribution])\n",
    "\n",
    "ax.set_title('Feature marginal contribution')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='x', colors='gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDP plots\n",
    "- PDP = Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:41.486682Z",
     "start_time": "2021-12-04T18:51:41.475647Z"
    }
   },
   "outputs": [],
   "source": [
    "def partial_dependency(bst, X, y, feature_names, feature_ids = [], f_id = -1):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the dependency (or partial dependency) of a response variable on a predictor (or multiple predictors)\n",
    "    1. Sample a grid of values of a predictor.\n",
    "    2. For each value, replace every row of that predictor with this value, calculate the average prediction.\n",
    "    \"\"\"\n",
    "    X_temp = X.copy()\n",
    "    grid = np.linspace(\n",
    "        np.percentile(X_temp[:, f_id], 0.1),\n",
    "        np.percentile(X_temp[:, f_id], 99.5),\n",
    "        50\n",
    "    )\n",
    "    y_pred = np.zeros(len(grid))\n",
    "\n",
    "    if len(feature_ids) == 0 or f_id == -1:\n",
    "        print ('Input error!')\n",
    "        return\n",
    "    else:\n",
    "        for i, val in enumerate(grid):\n",
    "\n",
    "            X_temp[:, f_id] = val\n",
    "            data = xgb.DMatrix(X_temp, feature_names = feature_names)\n",
    "\n",
    "            y_pred[i] = np.average(bst.predict(data))\n",
    "\n",
    "    return grid, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:46.011344Z",
     "start_time": "2021-12-04T18:51:42.519843Z"
    }
   },
   "outputs": [],
   "source": [
    "lst_f = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
    "# cols_pred\n",
    "sampled_data = data.sample(frac=0.1, random_state=22)\n",
    "for f in lst_f:\n",
    "    f_id = cols_pred.index(f)\n",
    "    feature_ids = range(len(cols_pred))\n",
    "\n",
    "    mask = sampled_data[f].notnull()\n",
    "    grid, y_pred = partial_dependency(\n",
    "        booster,\n",
    "        sampled_data[mask][cols_pred].values,\n",
    "        sampled_data[mask][col_target].values,\n",
    "        feature_names = cols_pred,\n",
    "        feature_ids = feature_ids,\n",
    "        f_id = f_id\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    plt.subplots_adjust(left = 0.17, right = 0.94, bottom = 0.15, top = 0.9)\n",
    "\n",
    "    ax.plot(grid, y_pred, ls = '-', color = 'red', linewidth = 1.5, label='fit')\n",
    "\n",
    "    ax.set_xlim(min(grid), max(grid))\n",
    "    ax.set_ylim(0.98 * min(y_pred), 1.02 * max(y_pred))\n",
    "\n",
    "    ax.set_title(f)\n",
    "    ax.set_ylabel('Partial Dependence')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICE plots\n",
    "- ICE = Individual Conditional Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:46.749372Z",
     "start_time": "2021-12-04T18:51:46.735309Z"
    }
   },
   "outputs": [],
   "source": [
    "def ice_data(bst, dt, predictor, n_points=20):\n",
    "    X = dt.copy()\n",
    "    grid = np.linspace(\n",
    "        dt[predictor].quantile(0.01),\n",
    "        dt[predictor].quantile(0.99),\n",
    "        n_points\n",
    "    )\n",
    "    \n",
    "    y_pred = np.zeros((len(dt), len(grid)))\n",
    "\n",
    "    if len(feature_ids) == 0 or f_id == -1:\n",
    "        print ('Input error!')\n",
    "        return\n",
    "    else:\n",
    "        for i, val in enumerate(grid):\n",
    "            X[predictor] = val\n",
    "            data = xgb.DMatrix(X, feature_names = X.columns)\n",
    "\n",
    "            y_pred[:,i] = bst.predict(data)\n",
    "    return grid, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:51:50.994914Z",
     "start_time": "2021-12-04T18:51:47.351313Z"
    }
   },
   "outputs": [],
   "source": [
    "n_plots = 100\n",
    "cols_to_plot = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
    "\n",
    "sampled_data = data.sample(n=10000, random_state=22)\n",
    "\n",
    "for pred in cols_to_plot:\n",
    "    x, ice_data_plot = ice_data(booster, sampled_data[cols_pred], pred)\n",
    "\n",
    "    idx = np.random.randint(len(x), size=n_plots)\n",
    "    plt.plot(x, np.transpose(ice_data_plot[idx,:]), lw = 0.5, color = 'lightblue')\n",
    "    plt.plot(x, np.average(ice_data_plot[idx,:], axis = 0), lw = 2, ls = '--', color = 'blue', label = 'Partial dependance curve')\n",
    "    plt.title(pred)\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.xlabel('Values')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "- SHAP = SHapley Additive exPlanations\n",
    "- Original paper presenting SHAP values can be downloaded here: <a href=https://arxiv.org/abs/1705.07874 target=\"_blank\">SHAP values</a>\n",
    "- SHAP values are defined by following equation:\n",
    "$$ \\phi_i = \\sum_{S\\subseteq F\\setminus\\lbrace i \\rbrace} \\frac{|S|!(|F|-|S|-1)!}{|F|!} [f_{S\\cup \\lbrace i\\rbrace}(x_{S\\cup \\lbrace i\\rbrace})-f_S(x_S)] $$\n",
    "where:\n",
    "\n",
    "    - $F$ ... set of all model features\n",
    "    - $S$ ... $S \\subseteq F \\setminus\\lbrace i\\rbrace$\n",
    "    - $\\phi_i$ ... SHAP value for predictor $x_i$\n",
    "    - $f_S(x_S)$ ... output of model build on feature set $S$ given feature values $x_S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:16.059606Z",
     "start_time": "2021-12-04T18:51:51.801737Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:19.352886Z",
     "start_time": "2021-12-04T18:52:16.688607Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(data[cols_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:29.523033Z",
     "start_time": "2021-12-04T18:52:20.699484Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(shap_values, data[cols_pred], max_display=20, show=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:30.267114Z",
     "start_time": "2021-12-04T18:52:30.206114Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], data[cols_pred].iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:32.276946Z",
     "start_time": "2021-12-04T18:52:30.932358Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.plots._waterfall.waterfall_legacy(\n",
    "    expected_value=explainer.expected_value, \n",
    "    shap_values=shap_values[0, :], \n",
    "    feature_names=cols_pred, \n",
    "    max_display=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP interaction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:47.486270Z",
     "start_time": "2021-12-04T18:52:32.985909Z"
    }
   },
   "outputs": [],
   "source": [
    "Xd = xgb.DMatrix(data[train_mask][cols_pred].iloc[:1000], data[train_mask][col_target].iloc[:1000])\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_interaction_values = explainer.shap_interaction_values(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:51.969868Z",
     "start_time": "2021-12-04T18:52:48.751708Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,13))\n",
    "\n",
    "sns.heatmap(\n",
    "    data=np.mean(abs(shap_interaction_values[:, 0:20, 0:20]), axis=0), \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    xticklabels=cols_pred[0:20], \n",
    "    yticklabels=cols_pred[0:20],\n",
    "    cmap='winter',\n",
    "    vmax=0.05\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:52:52.980869Z",
     "start_time": "2021-12-04T18:52:52.571874Z"
    }
   },
   "outputs": [],
   "source": [
    "n_observations = 10000\n",
    "\n",
    "dt_shap = data.iloc[0:n_observations]\n",
    "dt_shap = dt_shap[cols_pred]\n",
    "shap.dependence_plot('AMT_GOODS_PRICE', shap_values[:n_observations], dt_shap, interaction_index = 'AMT_CREDIT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
