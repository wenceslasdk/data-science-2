{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e803f8c",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ac5ec",
   "metadata": {},
   "source": [
    "Download the data from <a href=\"https://www2.karlin.mff.cuni.cz/~kozmikk/files/weatherAUS.zip\" target=\"_blank\"> weather data</a> and unpack it to the Data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cdc245",
   "metadata": {},
   "source": [
    "# Decision Trees & Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acffff43",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this tutorial we learn how to train CART, CHAID decision trees and random forests on real data and how to evaluate them. We also create simple random forest.\n",
    "\n",
    "We proceed as follows:\n",
    "\n",
    "- import data and handle missing values\n",
    "- split data to train and test samples using stratification\n",
    "- separately for CART and CHAID models we perform\n",
    "    - train decision tree and assess the performance\n",
    "    - inspect importance of predictors (available for CART only)\n",
    "    - evaluate the model performance in time\n",
    "- based on CART tree we manually construct random forest\n",
    "- we create and assess random forest model separately using two different encodings of categorical predictors\n",
    "    - one-hot encoding\n",
    "    - mean-target encoding\n",
    "    \n",
    "Additional resources:\n",
    "\n",
    "- https://towardsdatascience.com/cart-classification-and-regression-trees-for-clean-but-powerful-models-cc89e60b7a85\n",
    "- https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "- https://github.com/WillKoehrsen/Data-Analysis\n",
    "\n",
    "    \n",
    "Implementation limitations: CART only supports continuous predictors, whereas CHAID supports only categorical (either nominal or ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eb940",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import CHAID\n",
    "\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac742a5",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Weather data from Australia. The task is to predict if tomorrow is going to rain based on today's weather characteristics.\n",
    "\n",
    "Source: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "**Target description**\n",
    "\n",
    "- RainTomorrow: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0 for the next day\n",
    "\n",
    "**Predictors description**\n",
    "\n",
    "- MinTemp: The minimum temperature in degrees celsius\n",
    "- MaxTemp: The maximum temperature in degrees celsius\n",
    "- Sunshine: The number of hours of bright sunshine in the day.\n",
    "- WindGustSpeed: The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "- Humidity9am: Humidity (percent) at 9am\n",
    "- Humidity3pm: Humidity (percent) at 3pm\n",
    "- Pressure9am: Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "- Pressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "- RainToday: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d525d41",
   "metadata": {},
   "source": [
    "We import data and keep only several columns for simplicity and certain time period for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662aa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data_all = pd.read_csv('.\\..\\Data\\weatherAUS.csv', encoding='utf-8')\n",
    "\n",
    "# Keep only specified columns and rows\n",
    "columns = [\"Date\", \"MinTemp\", \"MaxTemp\", \"Sunshine\", \"WindGustSpeed\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"RainToday\", \"RainTomorrow\"]\n",
    "data = data_all.loc[data_all['Date']>='2016-01-01', columns]\n",
    "\n",
    "# Convert date to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "print(f'Number of rows:      {data.shape[0]}')\n",
    "print(f'Number of columns:   {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899713f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e5c69",
   "metadata": {},
   "source": [
    "# CART\n",
    "\n",
    "Implementation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "We use implementation from sci-kit learn package. The implementation has several characteristics:\n",
    "\n",
    "- Missing values are not supported\n",
    "- Assumes the predictors to be numeric variables (either continuous or ordinal categories). \n",
    "- Both categorical and continuous targets are possible (we chose either DecisionTreeClassification or DecisionTreeRegression class according to our task)\n",
    "\n",
    "Short description:\n",
    "\n",
    "In each node we iterate over randomly chosen set of predictors and compute gain for each predictors measured using defined measure and assuming different possible splits over this predictor. Using the best predictor we perform split into two subtrees. See details of the implementation for further parameters that influence stopping of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8b7ce",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dce61b",
   "metadata": {},
   "source": [
    "We copy our data to 'data_cart' dataframe.\n",
    "\n",
    "First, we handle missing values, then encode all predictors as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8598408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cart = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5b1d1",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba893b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of missing values in each column\n",
    "data_cart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values for both predictors and target\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa00d5c",
   "metadata": {},
   "source": [
    "### Predictor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35459ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check the format of the data\n",
    "data_cart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encode. Column 'Date' will not be used for prediction, therefore, no need to encode it. Only 'RainToday' and 'RainTomorrow' should be re-encoded.\n",
    "\n",
    "# TODO: Convert values of 'RainToday' and 'RainTomorrow' into 0-1 encoding. You can use .apply function to use row-by-row notation.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We denote 'target' the name of the column with target values. 'predictors' stands for the list of all predictors\n",
    "\n",
    "target = 'RainTomorrowFlag'\n",
    "\n",
    "predictors = columns.copy()\n",
    "predictors.remove('Date')\n",
    "predictors.remove('RainToday')\n",
    "predictors.remove('RainTomorrow')\n",
    "predictors += [\"RainTodayFlag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488ac21",
   "metadata": {},
   "source": [
    "## Split & train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88a59a",
   "metadata": {},
   "source": [
    "We split the data into train and test datasets. We use stratification by 'Month' for further model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have only one year of observations, therefore only numbers 1-12 can be used to encode month.\n",
    "data_cart['Month'] = data_cart['Date'].dt.month\n",
    "data_cart['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7989392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into 'data_cart_train' and 'data_cart_test' datasets. Use stratification by 'Month'.\n",
    "# Use function 'train_test_split' from 'sklearn.model_selection' package and choose parameters carefully.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3978ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the model.\n",
    "\n",
    "# TODO: Check the documentation for parameters' interpretation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "# Build the model and choose the parameters carefully.\n",
    "\n",
    "criterion = ...\n",
    "splitter = ...\n",
    "mdepth = ...\n",
    "min_samples_split = ...\n",
    "min_samples_leaf = ...\n",
    "minleaf = ...\n",
    "random_state = 17\n",
    "\n",
    "# Now we contruct the model.\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion=criterion,\n",
    "    splitter=splitter, \n",
    "    max_depth=mdepth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf, \n",
    "    random_state=random_state, \n",
    ")\n",
    "\n",
    "# And fit training data.\n",
    "\n",
    "clf = model.fit(data_cart_train[predictors], data_cart_train[target])\n",
    "\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = model.predict(data_cart_train[predictors])\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = model.predict(data_cart_test[predictors])\n",
    "\n",
    "# Tree summary and model evaluation metrics\n",
    "print('*************** Tree Summary ***************')\n",
    "print('Classes: ', clf.classes_)\n",
    "print('Tree Depth: ', clf.tree_.max_depth)\n",
    "print('No. of leaves: ', clf.tree_.n_leaves)\n",
    "print('No. of features: ', clf.n_features_)\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "\n",
    "print('*************** Evaluation on Test Data ***************')\n",
    "score_te = model.score(data_cart_test[predictors], data_cart_test[target])\n",
    "print('Accuracy Score: ', score_te)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(data_cart_test[target], pred_labels_te))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "\n",
    "print('*************** Evaluation on Training Data ***************')\n",
    "score_tr = model.score(data_cart_train[predictors], data_cart_train[target])\n",
    "print('Accuracy Score: ', score_tr)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(data_cart_train[target], pred_labels_tr))\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the tree structure.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "tree.plot_tree(clf, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f04cb",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc0460",
   "metadata": {},
   "source": [
    "We evaluate performance\n",
    "\n",
    "- we inspect accuracy of the predictions on test data month by month\n",
    "- we evaluate predictors importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3bdd2f",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f26113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Predict target variable on test data in two steps\n",
    "# - use 'predict_proba' method for 'DecisionTreeClassifier'\n",
    "# - convert result to 0/1 values using some threshold (could be done in one step but we want to observer dependence on the threshold)\n",
    "# Finally store the prediction as 'Prediction' column\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute accuracy by 'Month'. Store the result to pd.Series 'data_cart_accuracy'\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d68c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect stability of the model performance in time\n",
    "\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.bar(range(len(data_cart_accuracy)), data_cart_accuracy)\n",
    "ax1.set_xticks(range(len(data_cart_accuracy)))\n",
    "ax1.set_xticklabels(data_cart_accuracy.index, rotation = 90)\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4694669",
   "metadata": {},
   "source": [
    "### Predictor importance\n",
    "\n",
    "In scikit-learn the feature importance is the decrease in node impurity. The key is that it measures the importance only at a node level. Then, all the nodes are weighted by how many samples reach that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386afd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(clf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(predictors, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, predictors, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13806808",
   "metadata": {},
   "source": [
    "# CHAID\n",
    "\n",
    "Implementation: https://github.com/Rambatino/CHAID\n",
    "\n",
    "Documentation: https://www2.karlin.mff.cuni.cz/~kozmikk/files/TREE-CHAID.pdf\n",
    "\n",
    "- supports missing values for predictors (treated as a category)\n",
    "- assumes the predictors to be categorical (either nominal or ordinal)\n",
    "- the same implementation works also for regression (choose the dependent variable to be continuous)\n",
    "\n",
    "Short description:\n",
    "\n",
    "Continuous predictors are assumed to be categorized either in 'nominal' or 'ordinal' (e.g. deciles) format. Target is either 'nominal' or 'continuous'.\n",
    "\n",
    "We define constants alpha_merge and split_threshold.\n",
    "\n",
    "In each node we iterate over all categories of all predictors and test if they significantly influence the target value in terms of Chi-square test if target is 'categorical' or F-test if target is continuous. Categories are merged until the significance is below alpha_merge. Now we iterate over such newly categorized predictors and split using the one with the most significant influence on target (using the same measure as above) if split_threshold is triggered by any of them. We obtain possibly split which is non-binary.\n",
    "\n",
    "Additional parameters:\n",
    "\n",
    "- the above procedure is repeated only until the depth of the tree is not larger then max_depth\n",
    "- if we have less then min_parent_node_size in given node, no splitting is performed\n",
    "- if splitting would result in new node with less then min_child_node_size observations, no splitting is performed\n",
    "- if is_exhaustive is true then all possible merging combinations of given predictor's categories are examined (according to https://www.researchgate.net/publication/332591728_Classification_of_air_traffic_control_scenarios_using_decision_trees_insights_from_a_field_study_in_terminal_approach_radar_environment, note that the significance is adjusted using Bonferroni method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb1e0f",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc65ab8",
   "metadata": {},
   "source": [
    "We copy our data to 'data_chaid' dataframe.\n",
    "\n",
    "First, we handle missing values, then encode all predictors as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chaid = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1758e",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13afe2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values for both predictors and target\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c46671",
   "metadata": {},
   "source": [
    "### Predictor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0397107",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chaid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encode. Column 'Date' will not be used for prediction, therefore, no need to encode it. Only 'RainToday' and 'RainTomorrow' should be re-encoded.\n",
    "\n",
    "# TODO: Convert values of 'RainToday' and 'RainTomorrow' into 0-1 encoding. You can use .apply function to use row-by-row notation.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'RainTomorrowFlag'\n",
    "\n",
    "predictors_chaid = list(data_chaid.columns)\n",
    "predictors_chaid.remove('Date') # Date will not be used for training\n",
    "predictors_chaid.remove('RainToday') # We use RainTodayFlag instead\n",
    "predictors_chaid.remove('RainTomorrow') # Target\n",
    "predictors_chaid.remove('RainTomorrowFlag') # Target# We denote 'target' the name of the column with target values. 'predictors' stands for the list of all predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column 'Month' for future evaluation of the model performance in time\n",
    "data_chaid['Month'] = data_chaid['Date'].dt.month\n",
    "data_chaid['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8576fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check the predictors if we can assume that these are continuous\n",
    "\n",
    "for predictor in predictors_chaid:\n",
    "    \n",
    "    plt.hist(data_chaid[predictor], density=True, bins=10)  # density=False would make counts\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(predictor);\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac0382",
   "metadata": {},
   "source": [
    "## Split & categorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394bc90",
   "metadata": {},
   "source": [
    "Based on the histograms above we conclude that some of the predictors must be categorized. We do the categorization based on training data only, therefore, now we have to split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data, stratify by month\n",
    "data_chaid_train, data_chaid_test = train_test_split(\n",
    "    data_chaid, test_size=0.2, random_state=17, stratify=data_chaid['Month']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 'RainTodayFlag' predictor is categorical. The rest is continuous, therefore we have to categorize.\n",
    "\n",
    "n_cat = 10 # number of categories created for each predictor\n",
    "\n",
    "# We store categorized predictors from 'predictors_chaid' to 'predictors_chaid_cat' columns.\n",
    "\n",
    "predictors_chaid_cat = []\n",
    "for predictor in predictors_chaid:\n",
    "    \n",
    "    predictor_cat = predictor+'_cat'\n",
    "    predictors_chaid_cat.append(predictor_cat)\n",
    "    \n",
    "    if (predictor not in ['RainTodayFlag']): # 'RainTodayFlag' need not to be categorized\n",
    "        \n",
    "        # TODO: Categorize given predictor 'predictor' by quantiles using function pd.qcut with 'n_cat' categories. \n",
    "        # Note that in the future we will need to categorize also test data, therefore, label the\n",
    "        # new categories by right-end-point of each interval (np.infty for infinity).\n",
    "        ...\n",
    "        \n",
    "    else:\n",
    "        # Already categorized\n",
    "        data_chaid_train[predictor_cat] = data_chaid_train[predictor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1b02c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the model.\n",
    "\n",
    "# The model needs to know if 'ordinal' or 'nominal' predictors are present (only 'nominal' in our case as we have also missing values)\n",
    "independent_columns = dict(zip(predictors_chaid_cat, ['nominal'] * len(predictors_chaid_cat)))\n",
    "\n",
    "# TODO: Choose the parameters carefully. See the algorithm description above.\n",
    "config_chaid = {\n",
    "    'alpha_merge': ..., # minimum significance level for categories not to be merged\n",
    "    'max_depth': ..., #maximum depth of tree\n",
    "    'min_parent_node_size': ..., # minimum number of observations of node for splitting\n",
    "    'min_child_node_size': ..., # minimum number of observations in new node\n",
    "    'split_threshold': ..., # minimum gain for new split\n",
    "}\n",
    "\n",
    "tree_ch = CHAID.Tree.from_pandas_df(\n",
    "    data_chaid_train,\n",
    "    independent_columns,\n",
    "    target,\n",
    "    alpha_merge = config_chaid['alpha_merge'],\n",
    "    max_depth = config_chaid['max_depth'],\n",
    "    min_parent_node_size = config_chaid['min_parent_node_size'],\n",
    "    min_child_node_size = config_chaid['min_child_node_size'],\n",
    "    split_threshold = config_chaid['split_threshold'],\n",
    ")\n",
    "\n",
    "# Tree summary and model evaluation metrics\n",
    "print('*************** Tree Summary ***************')\n",
    "print('Classes: ', len(data_chaid_train[target].unique()))\n",
    "print('Tree Depth: ', tree_ch.max_depth)\n",
    "print('No. of features: ', len(independent_columns))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "\n",
    "print('*************** Evaluation on Training Data ***************')\n",
    "print('Accuracy Score: ', tree_ch.accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66317421",
   "metadata": {},
   "source": [
    "Note: features_importance not available in this implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530915a",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c7a52",
   "metadata": {},
   "source": [
    "We evaluate performance of the model using accuracy month by month.\n",
    "\n",
    "Before we can predict for test data, we have to use the same categorization as for the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea750f",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to categorize the train data in the same way as we have categorized the train data\n",
    "\n",
    "for predictor in predictors_chaid:\n",
    "    \n",
    "    predictor_cat = predictor+'_cat'\n",
    "    \n",
    "    if (predictor not in ['RainTodayFlag']): # 'RainTodayFlag' need not be categorized\n",
    "        \n",
    "        # TODO: Categorize predictor 'predictor' using intervals from train data. Use the function\n",
    "        # pd.cut.\n",
    "        labels=list(data_chaid_train[predictor_cat].unique()) # We take the right-end points of intervals from train data\n",
    "        labels = sorted([x for x in labels if str(x) != 'nan']) # We drop 'nan' end point which stands for missing values\n",
    "        bins = [-np.inf] + labels\n",
    "        data_chaid_test[predictor_cat] = ...\n",
    "    else:\n",
    "        # Already categorized\n",
    "        data_chaid_test[predictor_cat] = data_chaid_test[predictor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c80efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disclaimer: The implementation does not involve method for prediction. Therefore, we use our own implementation.\n",
    "\n",
    "# Leaves of the tree: list of leaves with rules\n",
    "leaves = tree_ch.classification_rules() # Contains rules for leaves\n",
    "nodes = tree_ch.tree_store # Contains predictions for all nodes (not only leaves)\n",
    "\n",
    "def chaid_predict(data):\n",
    "    \"\"\"\n",
    "        Returns prediction of 'target' using trained CHAID tree for one observation by identifying correct leaf.\n",
    "        \n",
    "        Args:\n",
    "            one observation as in format 'data_chaid' with columns 'predictors_chaid_cat'\n",
    "        \n",
    "        Returns:\n",
    "            float: number of positive cases in identified leaf/number of total cases in identified leaf\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over all leaves of the tree and find the correct one\n",
    "    for leaf in leaves:\n",
    "        \n",
    "        # List of rules that determine the leaf\n",
    "        rules = leaf['rules']\n",
    "        rule_i = 0\n",
    "\n",
    "        # Evaluate conditions until one fails\n",
    "        is_member = True\n",
    "        while is_member and (rule_i+1<=len(rules)):\n",
    "            \n",
    "            \n",
    "            var_name = rules[rule_i]['variable']\n",
    "            var_val_list = rules[rule_i]['data']\n",
    "            \n",
    "            if data[var_name] not in var_val_list:\n",
    "                is_member = False\n",
    "            \n",
    "            rule_i = rule_i+1\n",
    "            \n",
    "        if is_member: # All conditions met\n",
    "            \n",
    "            zeros = nodes[leaf['node']]._members[0]\n",
    "            ones = nodes[leaf['node']]._members[1]\n",
    "            \n",
    "            return ones/(zeros+ones)\n",
    "        \n",
    "    return None # No leaf found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Predict target variable on test data in two steps\n",
    "# - use 'chaid_predict' to compute prediction as probability\n",
    "# - convert result to 0/1 values using some threshold (could be done in one step but we want to observer dependence on the threshold)\n",
    "# Finally store the prediction as 'Prediction' column\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1ced3",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc44a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy by 'Month'\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect stability of the model performance in time\n",
    "\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.bar(range(len(data_chaid_accuracy)), data_chaid_accuracy)\n",
    "ax1.set_xticks(range(len(data_chaid_accuracy)))\n",
    "ax1.set_xticklabels(data_chaid_accuracy.index)\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b1802",
   "metadata": {},
   "source": [
    "# Random forest - manually\n",
    "\n",
    "We build our own random forest based on one of the above trees. This includes randomly selecting predictors and observations for the training.\n",
    "\n",
    "The forest consists of CART trees each trained on a fraction of training data. We observe accuracy on data not used when training given tree (validation data) and assess the whole forest by accuracy on separate test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dfdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta parameters\n",
    "target = 'RainTomorrowFlag'\n",
    "\n",
    "n_models = 10 # Number of trees in ensemble\n",
    "p_obs = 0.3 # Prob. that observation is chosen for training of a given tree\n",
    "\n",
    "# TODO: Adjust parameters as above. Note that reasonable forest should consist of trees with distinct random seeds.\n",
    "criterion = 'gini' #(TODO)\n",
    "splitter = 'best' #(TODO)\n",
    "mdepth = 4 #(TODO)\n",
    "min_samples_split = 5 #(TODO)\n",
    "min_samples_leaf = 0.001 #(TODO)\n",
    "minleaf = 100 #(TODO)\n",
    "\n",
    "\n",
    "# We fit 'n_models' models and store them into list\n",
    "clf_list = []\n",
    "for n in range(n_models):\n",
    "    \n",
    "    # TODO: Define 'train_index' a list of indices from 'data_cart_train' to be used for training in given iteration, consider parameter 'p_obs'\n",
    "    train_index = random.sample(list(data_cart_train.index), int(p_obs*len(data_cart_train))) #(TODO)\n",
    "\n",
    "    # Init the model\n",
    "    model = tree.DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        splitter=splitter, \n",
    "        max_depth=mdepth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf, \n",
    "        random_state=n,\n",
    "    )\n",
    "\n",
    "    clf = model.fit(data_cart_train.loc[train_index, predictors], data_cart_train.loc[train_index, target])\n",
    "    \n",
    "    clf_list = clf_list + [model]\n",
    "\n",
    "    if n==0:\n",
    "        # Tree summary and model evaluation metrics\n",
    "        print('*************** Tree Summary ***************')\n",
    "        print('Classes: ', clf.classes_)\n",
    "        print('Tree Depth: ', clf.tree_.max_depth)\n",
    "        print('No. of leaves: ', clf.tree_.n_leaves)\n",
    "        print('No. of features: ', clf.n_features_)\n",
    "        print('--------------------------------------------------------')\n",
    "        print(\"\")\n",
    "        \n",
    "        # TODO: Compute predictions using model.predict_proba for 'data_cart_train' and 'data_cart_test' in the first iteration\n",
    "        data_cart_train['Prediction_forest_prob'] = model.predict_proba(data_cart_train[predictors])[:,1] #(TODO)\n",
    "        data_cart_test['Prediction_forest_prob'] = model.predict_proba(data_cart_test[predictors])[:,1] #(TODO)\n",
    "    \n",
    "    else:\n",
    "        # TODO: Compute predictions using model.predict_proba for 'data_cart_train' and 'data_cart_test' after the first iteration\n",
    "        data_cart_train['Prediction_forest_prob'] = 1/(n+1)*(data_cart_train['Prediction_forest_prob']*n + model.predict_proba(data_cart_train[predictors])[:,1]) #(TODO)\n",
    "        data_cart_test['Prediction_forest_prob'] = 1/(n+1)*(data_cart_test['Prediction_forest_prob']*n + model.predict_proba(data_cart_test[predictors])[:,1]) #(TODO)\n",
    "    \n",
    "    # TODO: Use threshold to transform probabilities to 0/1 values and store prediction as 'Prediction_forest' column in 'data_cart_train' and 'data_cart_test' datasets\n",
    "    data_cart_train['Prediction_forest'] = (data_cart_train['Prediction_forest_prob']>=0.5).astype(int)\n",
    "    data_cart_test['Prediction_forest'] = (data_cart_test['Prediction_forest_prob']>=0.5).astype(int)\n",
    "\n",
    "    print('*************** Evaluation After Iteration '+str(n+1)+' *********')\n",
    "    score_te = 1-abs(data_cart_train['Prediction_forest']-data_cart_train[target]).mean()\n",
    "    print('Accuracy Train: ', score_te)\n",
    "    score_tr = 1-abs(data_cart_test['Prediction_forest']-data_cart_test[target]).mean()\n",
    "    print('Accuracy Valid: ', score_tr)\n",
    "    print('--------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3515ffc",
   "metadata": {},
   "source": [
    "Now we evaluate the performance of our forest. Prediction is simple average of predictions over different trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555912b",
   "metadata": {},
   "source": [
    "# Bonus task\n",
    "\n",
    "Use different approach for training our random forest: Choose randomly predictors which will be used for training each of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94dc03",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12ae99",
   "metadata": {},
   "source": [
    "For this task we use different data points from the same dataset as above. Therefore, we reload the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44835e",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Weather data from Australia. The task is to predict if tomorrow is going to rain based on today's weather characteristics.\n",
    "\n",
    "Source: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "**Target description**\n",
    "\n",
    "- MaxTemp: The maximum temperature in degrees celsius\n",
    "\n",
    "**Predictors description**\n",
    "\n",
    "- Rainfall: The amount of rainfall recorded for the day in mm\n",
    "- Evaporation: The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "- Sunshine: The number of hours of bright sunshine in the day.\n",
    "- Location: The common name of the location of the weather station\n",
    "- WindGustSpeed: The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "- WindDir9am: Direction of the wind at 9am\n",
    "- WindDir3pm: Direction of the wind at 3pm\n",
    "- Humidity9am:Humidity (percent) at 9am\n",
    "- Humidity3pm: Humidity (percent) at 3pm\n",
    "- Pressure9am: Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "- Pressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "- Cloud9am: Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast.\n",
    "- Clousd3pm: Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ec957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv('.\\..\\Data\\weatherAUS.csv', encoding='utf-8')\n",
    "\n",
    "# Keep only specified columns and rows\n",
    "columns = [\"Rainfall\", \"Evaporation\", \"Sunshine\", \"Location\", \"WindGustSpeed\", \"WindDir9am\", \"WindDir3pm\", \"Humidity9am\", \"Humidity3pm\",  \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"MaxTemp\"]\n",
    "data_forest = data.loc[data['Location'].isin([\"Canberra\", \"Sydney\", \"Albury\"]), columns]\n",
    "\n",
    "print(f'Number of rows:      {data_forest.shape[0]}')\n",
    "print(f'Number of columns:   {data_forest.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_forest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501991d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics: note that only numerical features are included\n",
    "data_forest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f544f",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values in each column\n",
    "data_forest.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8142e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We treat numerical and categorical features differently\n",
    "data_forest.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We denote 'target' the name of the column with target values. \n",
    "# 'predictors_cat' stands for the list categorical predictors\n",
    "# 'predictors_num' stands for the list numerical predictors\n",
    "\n",
    "target = \"MaxTemp\"\n",
    "\n",
    "predictors_cat = list(data_forest.columns[[data_forest[col].dtype == 'object' for col in data_forest.columns]])\n",
    "predictors_num = list(data_forest.columns[[data_forest[col].dtype != 'object' for col in data_forest.columns]])\n",
    "predictors_num.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b225ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target\n",
    "data_forest=data_forest[pd.isnull(data_forest[target])==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f889e36",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31452d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:  Handle missing values for predictors\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2a499",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "\n",
    "Two possible approaches:\n",
    "\n",
    "- one-hot encoding\n",
    "- mean-target encoding\n",
    "\n",
    "We investigate both of them separately.\n",
    "\n",
    "After this section, predictors_one_hot contain predictors_cat one-hot-encoded and predictors_mean_target contain predictors_cat mean-target-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49192d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding. Names of columns of new columns will be stored in 'predictors_one_hot'\n",
    "\n",
    "predictors_one_hot = []\n",
    "for pred in predictors_cat:\n",
    "    \n",
    "    # TODO: Use pd.get_dummies to encode categorical predictors. Store the result to 'data_one_hot' dataframe\n",
    "    # (only columns containing encoded values)\n",
    "    ...\n",
    "    \n",
    "    # Join to data\n",
    "    data_forest = pd.concat([data_forest, data_one_hot], axis=1)\n",
    "    \n",
    "    # Keep new predictors names\n",
    "    predictors_one_hot = predictors_one_hot + list(data_one_hot.columns)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117a58f",
   "metadata": {},
   "source": [
    "Now, we create function that computes encoding values for given predictor.\n",
    "\n",
    "For binary target, the encoding for given predictor and category is given as a convex combination of mean target value for observations in the category and mean target value for the whole dataset:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\frac{count_{cat}}{count_{all}}*mean\\_target_{cat}+\\alpha*mean\\_target_{all}}{\\frac{count_{cat}}{count_{all}}+\\alpha},\n",
    "\\end{align*}\n",
    "where $\\alpha$ is a chosen parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-target encoding\n",
    "\n",
    "def mean_target_encoding(data, predictor, target, alpha = 0.01):\n",
    "    \n",
    "    \"\"\"\n",
    "    - Args:\n",
    "        data: dataset\n",
    "        predictor: column name for predictor in data to be encoded\n",
    "        target: column name for target\n",
    "        alpha: parameter in mean-target-encoding (float)\n",
    "        \n",
    "    - Returns:\n",
    "        Dict: key = category in 'predictor', value = encoded category based on 'target' using mean-target encoding with parameter 'alpha'\n",
    "    \"\"\"\n",
    "    \n",
    "    #data[predictor] = data[predictor].fillna(\"MISSING\")\n",
    "    \n",
    "    # TODO: Create dataframe category that contains at least two columns:\n",
    "    # column predictor (use the parameter of the function) contains unique category values for given predictor\n",
    "    # column 'encoding' contains mean-target-encoding for given category computed as above\n",
    "    # Keep in mind, that whenever you apply 'groupby' you have to specify 'dropna'=False to keep also observations with missing values\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # Create dictionary storing our encoding\n",
    "    encoding = dict(zip(category.index,category['encoding']))\n",
    "    \n",
    "    return encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a995fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding. Names of columns of new columns will be stored in 'predictors_mean_target'\n",
    "\n",
    "predictors_mean_target = []\n",
    "encodings = {}\n",
    "for pred in predictors_cat:\n",
    "    \n",
    "    # New predictor name contains 'MT' and former predictor name\n",
    "    pred_mean_target = pred + \"MT\"\n",
    "    \n",
    "    # TODO: First, compute the encoding for given predictor. Then apply using 'replace' method\n",
    "    # that works on data frames and store values to 'data_forest[pred_mean_target]'\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # Keep new predictors names\n",
    "    predictors_mean_target = predictors_mean_target + [pred_mean_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ba156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect mean-target encoding\n",
    "\n",
    "for pred in predictors_mean_target:\n",
    "    \n",
    "    temp = encodings[pred]\n",
    "    \n",
    "    # Pyplot does not handle missing values, for some predictors we have to refactor (Warning: this code is data-specific)\n",
    "    if pred != 'LocationMT':\n",
    "        pom = list(temp.keys())[-1]\n",
    "        temp['nan'] = temp.pop(pom)\n",
    "    \n",
    "    # Plot\n",
    "    ax1 = plt.subplot(111)\n",
    "    ax1.bar(range(len(temp)), list(temp.values()))\n",
    "    ax1.set_xticks(range(len(temp)))\n",
    "    ax1.set_xticklabels(temp.keys(), rotation=60)\n",
    "    ax1.set_xlabel('Category')\n",
    "    ax1.set_ylabel('Mean-target')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e4f68",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "We train separately based on different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data. We produce datasets for one-hot and mean-target encodings separately\n",
    "\n",
    "# One-hot encoding\n",
    "X_train_oh, X_test_oh, y_train_oh, y_test_oh = train_test_split(\n",
    "    data_forest[predictors_num+predictors_one_hot], data_forest[target], test_size=0.2, random_state=17\n",
    ")\n",
    "\n",
    "# Mean-target encoding\n",
    "X_train_mt, X_test_mt, y_train_mt, y_test_mt = train_test_split(\n",
    "    data_forest[predictors_num+predictors_mean_target], data_forest[target], test_size=0.2, random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfe308",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use 'sklearn' documentation to carefully choose parameters, init and fit the model. Use 'X_train_oh' and 'y_train_oh' data defined above.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3f854",
   "metadata": {},
   "source": [
    "### Mean-target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768aa920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use 'sklearn' documentation to carefully choose parameters, init and fit the model. Use 'X_train_mt' and 'y_train_mt' data defined above.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80622f5d",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We evaluate both models based on MAE, MAPE and visually by inspecting the prediction errors. We also consider features' importance.\n",
    "\n",
    "In scikit-learn the feature importance is the decrease in node impurity. The key is that it measures the importance only at a node level. Then, all the nodes are weighted by how many samples reach that node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133852c",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions_oh = rf_oh.predict(X_test_oh)\n",
    "\n",
    "# Calculate MAE\n",
    "absolute_error_oh = abs(predictions_oh - y_test_oh)\n",
    "MAE_oh = round(np.mean(absolute_error_oh), 2)\n",
    "\n",
    "# Calculate MAPE\n",
    "absolute_percentage_error_oh = 100 * (absolute_error_oh / y_test_oh)\n",
    "MAPE_oh = round(np.mean(absolute_percentage_error_oh), 2)\n",
    "\n",
    "# Print\n",
    "print('Mean Absolute Error:', MAE_oh, 'degrees.')\n",
    "print('Mean Absolute Percentage Error:', MAPE_oh, '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances_oh = list(rf_oh.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_oh = [(feature, round(importance, 2)) for feature, importance in zip(predictors_num+predictors_one_hot, importances_oh)]\n",
    "\n",
    "# Sort the feature importances by most important first and take only 10 most powerful\n",
    "feature_importances_oh = sorted(feature_importances_oh, key = lambda x: x[1], reverse = True)[:10]\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances_oh];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffb9f9",
   "metadata": {},
   "source": [
    "### Mean target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions_mt = rf_mt.predict(X_test_mt)\n",
    "\n",
    "# Calculate MAE\n",
    "absolute_error_mt = abs(predictions_mt - y_test_mt)\n",
    "MAE_mt = round(np.mean(absolute_error_mt), 2)\n",
    "\n",
    "# Calculate MAPE\n",
    "absolute_percentage_error_mt = 100 * (absolute_error_mt / y_test_mt)\n",
    "MAPE_mt = round(np.mean(absolute_percentage_error_mt), 2)\n",
    "\n",
    "# Print\n",
    "print('Mean Absolute Error:', MAE_mt, 'degrees.')\n",
    "print('Mean Absolute Percentage Error:', MAPE_mt, '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f30a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances_mt = list(rf_mt.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_mt = [(feature, round(importance, 2)) for feature, importance in zip(predictors_num+predictors_mean_target, importances_mt)]\n",
    "\n",
    "# Sort the feature importances by most important first and take only 10 most powerful\n",
    "feature_importances_mt = sorted(feature_importances_mt, key = lambda x: x[1], reverse = True)[:10]\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances_mt];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee72ea2c",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise prediction errors. Namely, we plot difference in residuals of the two models against target value in scatter plot.\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "ax1.scatter(y_test_mt, predictions_mt-predictions_oh)\n",
    "ax1.set_xlabel('Target', size=20)\n",
    "ax1.set_ylabel('Errors difference (mean-target - one-hot)', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4818d",
   "metadata": {},
   "source": [
    "## Un-observed value\n",
    "\n",
    "Our aim now is to forecast at location which has not been observed in training data. For one-hot-encoding, we would have to re-train our model. If we use mean-target encoding, only target means have to be computed for the new category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import new dataset and keep values only for observation from 'Location'==\"Perth\".\n",
    "\n",
    "data_new = pd.read_csv('.\\..\\Data\\weatherAUS.csv', encoding='utf-8')\n",
    "\n",
    "columns = [\"Rainfall\", \"Evaporation\", \"Sunshine\", \"Location\", \"WindGustSpeed\", \"WindDir9am\", \"WindDir3pm\", \"Humidity9am\", \"Humidity3pm\",  \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"MaxTemp\"]\n",
    "data_new = data_new.loc[data_new['Location'].isin([\"Perth\"]), columns]\n",
    "\n",
    "print(f'Number of rows:      {data_new.shape[0]}')\n",
    "print(f'Number of columns:   {data_new.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We handle missing values as previously\n",
    "data_new=data_new[pd.isnull(data_new[target])==False]\n",
    "data_new[predictors_num]=data_new[predictors_num].fillna(data_new[predictors_num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the following categorical predictors\n",
    "predictors_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 'WindDir9am' and 'WindDir3pm' can be encoded using previously estimated mean-targets. \n",
    "# As previously, store new predictors as 'data_new['WindDir9amMT']', 'data_new['WindDir3pmMT']'\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'Location' that contains previously unobserved value, we have to compute encoding from scratch. We therefore recompute\n",
    "# all the encoding on both new and old data. New encoding can be used also for 'WindDir9am', 'WindDir3pm'.\n",
    "\n",
    "# For 'Location' we compute encodings for all categories but then apply only for \"Perth\".\n",
    "\n",
    "encodings_new = {}\n",
    "for pred in predictors_cat:\n",
    "    \n",
    "    # New predictor name contains 'MT' and former predictor name\n",
    "    pred_mean_target = pred + \"MT\"\n",
    "    \n",
    "    # TODO: First, compute the encoding for given predictor using both data_new and data_forest. \n",
    "    #Then apply using 'replace' method that works on data frames and store values to 'data_new[pred_mean_target]'\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoding vlues for 'Location' slightly change\n",
    "encodings['LocationMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_new['LocationMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf06b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can predict and evaluate MAE and MAPE\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions_mt_new = rf_mt.predict(data_new[predictors_num+predictors_mean_target])\n",
    "\n",
    "# Calculate MAE\n",
    "absolute_error_mt_new = abs(predictions_mt_new - data_new[target])\n",
    "MAE_mt_new = round(np.mean(absolute_error_mt_new), 2)\n",
    "\n",
    "# Calculate MAPE\n",
    "absolute_percentage_error_mt_new = 100 * (absolute_error_mt_new / data_new[target])\n",
    "MAPE_mt_new = round(np.mean(absolute_percentage_error_mt_new), 2)\n",
    "\n",
    "# Print\n",
    "print('Mean Absolute Error:', MAE_mt_new, 'degrees.')\n",
    "print('Mean Absolute Percentage Error:', MAPE_mt_new, '%.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
